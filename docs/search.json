[
  {
    "objectID": "dictionary/index.html",
    "href": "dictionary/index.html",
    "title": "The AI Dictionary",
    "section": "",
    "text": "I often find explanations online to be more complicated than they need to be. Here, I hope to fix that. New terms will continue to be added over time.\nClick terms to view expanded definitions.\nDo let me know of any corrections and improvements, and of any terms you would like added!\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nAccuracy\n\n\n\n\n\nA type of metric. It is a value that tells us how often a model produces correct predictions. The higher the accuracy, the better.\n\n\n\n\n\n\n\n\n\n\nActivation Function\n\n\n\n\n\nA function that follows the linear function in a neuron, to introduce nonlinearity.\n\n\n\n\n\n\n\n\n\n\nArchitecture\n\n\n\n\n\nA model that is used as a template or a starting point for another model.\n\n\n\n\n\n\n\n\n\n\nBackpropagation\n\n\n\n\n\nThe name given to the algorithm that computes the gradients for the weights in a model. Note that it does not update the weights, and hence is not an optimizer\n\n\n\n\n\n\n\n\n\n\nBackward Pass\n\n\n\n\n\nThe pass that begins with the outputs, and ends with the gradients. Also see forward pass.\n\n\n\n\n\n\n\n\n\n\nBagging\n\n\n\n\n\nAn ensembling technique. When bagging, each model is trained on random subset of the rows, and a random subset of the columns, with replacement.\n\n\n\n\n\n\n\n\n\n\nBatch\n\n\n\n\n\nA small collection of data from the dataset.\n\n\n\n\n\n\n\n\n\n\nCross Entropy Loss\n\n\n\n\n\nA technique for calculating the loss for categorical models with multiple categories.\n\n\n\n\n\n\n\n\n\n\nDataloader\n\n\n\n\n\nAn object that takes data from the dataset, and assembles them into batches. Note that this object does not decide what indices to load from, and hence is not a sampler.\n\n\n\n\n\n\n\n\n\n\nDataset\n\n\n\n\n\nA collection of data.\n\n\n\n\n\n\n\n\n\n\nDecision Tree\n\n\n\n\n\nA type of model that acts like an if-else statement.\n\n\n\n\n\n\n\n\n\n\nDecoder (Transformers)\n\n\n\n\n\nA component of a transformer that is used for generating text. An example is the autocomplete feature on a smartphone’s keyboard.\n\n\n\n\n\n\n\n\n\n\nDocument\n\n\n\n\n\nThe name given to a piece or collection of text. It can range from anything from a single word to a sentence to a paragraph to a page of text to a full book, and so on. Also referred to as sequence.\n\n\n\n\n\n\n\n\n\n\nDot Product\n\n\n\n\n\nThe operation given to the process of taking the product of each corresponding element in a vector, and summing all products. Also known as linear combination.\n\n\n\n\n\n\n\n\n\n\nEmbedding\n\n\n\n\n\nA table, or matrix, where each row represents an item and each column describes the items in some way. The real magic of embeddings happen when you combine two embeddings together in some way to obtain further information.\n\n\n\n\n\n\n\n\n\n\nEncoder (Transformers)\n\n\n\n\n\nA component of a transformer that is used for “understanding” text. Encoders are typically used for classifying sentences by sentiment and figuring out what parts of a sentence refers, for example, to a person or location.\n\n\n\n\n\n\n\n\n\n\nEnsemble\n\n\n\n\n\nA collection of models whos’ predictions are averaged to obtain the final prediction.\n\n\n\n\n\n\n\n\n\n\nError Rate\n\n\n\n\n\nA type of metric. It is a value that tells us how often a model produces incorrect predictions. The lower the error rate, the better.\n\n\n\n\n\n\n\n\n\n\nForward Pass\n\n\n\n\n\nThe pass that begins with the inputs, and ends with the outputs and loss. Also see backward pass.\n\n\n\n\n\n\n\n\n\n\nGradient\n\n\n\n\n\nA numerical value that informs us how to adjust a parameter of the model.\n\n\n\n\n\n\n\n\n\n\nGradient Accumulation\n\n\n\n\n\nA technique for running or fitting large models on a not-so-powerful GPU.\n\n\n\n\n\n\n\n\n\n\nGradient Boosting Machine (GBM)\n\n\n\n\n\nAn ensembling technique where instead of averaging the predictions of all models, each successive model predicts the error of the previous model. The errors are then summed to obtain the final prediction.\n\n\n\n\n\n\n\n\n\n\nInference\n\n\n\n\n\nUsing a trained model for predictions.\n\n\n\n\n\n\n\n\n\n\nK-Fold Cross Validation\n\n\n\n\n\nAn ensembling technique where models are trained on a different set percent of the dataset. For example each model is trained on a different 80% of the dataset.\n\n\n\n\n\n\n\n\n\n\nLatent (Diffusion)\n\n\n\n\n\nA compressed image.\n\n\n\n\n\n\n\n\n\n\nLearning Rate\n\n\n\n\n\nA numerical value which controls how much the gradients update the parameters of a model.\n\n\n\n\n\n\n\n\n\n\nLinear Combination\n\n\n\n\n\nThe operation given to the process of taking the product of each corresponding element in a vector, and summing all products. Also known as dot product.\n\n\n\n\n\n\n\n\n\n\nLoss\n\n\n\n\n\nA measure of performance of a model. It is used by the model to improve itself. Typically, the lower the loss, the better.\n\n\n\n\n\n\n\n\n\n\nMatrix\n\n\n\n\n\nA table of values. See also vector\n\n\n\n\n\n\n\n\n\n\nMean Absolute Error (MAE)\n\n\n\n\n\nA type of metric. It is a value that tells us, on average, how close a set of predicted values is from the actual values. The smaller the MAE, the better.\n\n\n\n\n\n\n\n\n\n\nMean Columnwise Root Mean Squared Error (MCRMSE)\n\n\n\n\n\nA metric used for those tasks where multiple targets need to be predicted. This metric simply takes the average of the RMSE of each target.\n\n\n\n\n\n\n\n\n\n\nMean Squared Error (MSE)\n\n\n\n\n\nA type of metric. It is a value that tells us, on average, how close a set of predicted values is from the actual values. The smaller the MSE, the better.\n\n\n\n\n\n\n\n\n\n\nMetric\n\n\n\n\n\nA measure of performance of a model. It is used by humans to judge the performance of the model.\n\n\n\n\n\n\n\n\n\n\nModel\n\n\n\n\n\nA mathematical equation that mimicks a real life phenomenon. This equation can be used to predict desired quantities.\n\n\n\n\n\n\n\n\n\n\nNamed Entity Recognition (NER)\n\n\n\n\n\nA NLP classification task where a sentence is broken into its components, and the model attempts to assign each component to a specific entity (e.g., person, place, organization).\n\n\n\n\n\n\n\n\n\n\nNeuron\n\n\n\n\n\nA basic processor of information. It consists of the linear combination and an activation function.\n\n\n\n\n\n\n\n\n\n\nNumericalization\n\n\n\n\n\nA process where numbers are assigned to each token. Occurs after tokenization.\n\n\n\n\n\n\n\n\n\n\nOne Hot Encoding\n\n\n\n\n\nA data processing technique where each class in a categorical feature is given its own column that contains true and false values.\n\n\n\n\n\n\n\n\n\n\nOneR Classifier\n\n\n\n\n\nThe simplest type of decision tree. The tree only contains a single split.\n\n\n\n\n\n\n\n\n\n\nOptimizer\n\n\n\n\n\nThe name given to the algorithm that updates the weights in a model. Note that it does not compute the gradients, and hence is not part of backpropagation.\n\n\n\n\n\n\n\n\n\n\nPolicy (Reinforcement Learning)\n\n\n\n\n\nThe strategy the agent uses to choose actions based on its current state. The chosen actions aim to maximize the reward.\n\n\n\n\n\n\n\n\n\n\nRandom Forest\n\n\n\n\n\nThe name given to a bagged ensemble of decision trees.\n\n\n\n\n\n\n\n\n\n\nRectified Linear Unit (ReLU)\n\n\n\n\n\nAn activation function that clips any value less than zero, to zero.\n\n\n\n\n\n\n\n\n\n\nRoot Mean Squared Error (RMSE)\n\n\n\n\n\nA type of metric. It is a value that tells us, on average, how close a set of predicted values is from the actual values. The smaller the RMSE, the better.\n\n\n\n\n\n\n\n\n\n\nRoot Mean Squared Logarithmic Error (RMSLE)\n\n\n\n\n\nA type of metric. It is a value that tells us, on average, how close a set of predicted values is from the actual values. The smaller the RMSLE, the better.\n\n\n\n\n\n\n\n\n\n\nSample\n\n\n\n\n\nA row in a dataset.\n\n\n\n\n\n\n\n\n\n\nSampler\n\n\n\n\n\nAn algorithm that decides what indices of a dataset to load. Note that this algorithm does not load data, and hence is not a dataloader.\n\n\n\n\n\n\n\n\n\n\nSequence\n\n\n\n\n\nThe name given to a piece or collection of text. It can range from anything from a single word to a sentence to a paragraph to a page of text to a full book, and so on. Also referred to as document.\n\n\n\n\n\n\n\n\n\n\nSoftmax\n\n\n\n\n\nA function that calculates the probabilities of a set of predictions.\n\n\n\n\n\n\n\n\n\n\nTabular Data\n\n\n\n\n\nData in the form of a table.\n\n\n\n\n\n\n\n\n\n\nTabular Model\n\n\n\n\n\nA model trained on tabular data. It is used to predict a specified column in the data.\n\n\n\n\n\n\n\n\n\n\nTokenization\n\n\n\n\n\nSplitting a document into its component words.\n\n\n\n\n\n\n\n\n\n\nTransformer\n\n\n\n\n\nThe name given to a Natural Language Processing (NLP) architecture that, in a nutshell, either fills-in-the-blanks or autocompletes text. Transformers consist of either an encoder, decoder, or both.\n\n\n\n\n\n\n\n\n\n\nVector\n\n\n\n\n\nA table of values that has either a single row or a single column. See also matrix.\n\n\n\n\n\n\n\n\n\n\nWeight Decay\n\n\n\n\n\nA technique for making sure weights do not grow too large, and in turn overfit the data.\n\n\n\n\n\n\n\n\n\n\nZero-shot\n\n\n\n\n\nA prefix given to a pretrained model that can be used without finetuning.\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/sequence.html",
    "href": "dictionary/terms/sequence.html",
    "title": "Sequence",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/mean_squared_error_mse.html",
    "href": "dictionary/terms/mean_squared_error_mse.html",
    "title": "Mean Squared Error (MSE)",
    "section": "",
    "text": "It is calculated by:\n\nFirst taking the difference between each respective predicted and actual value.\nThen the squaring all obtained values.\nAnd finally taking the average.\n\nLet’s say we have a set of predicted values \\(1, 2, 3, 4\\). The set of actual values is \\(1, 4, 3, 3\\)\n\n\\(1-1, 2-4, 3-3, 4-3, = 0, -2, 0, 1\\)\n\\((0)^2, (-2)^2, (0)^2, (1)^2 = 0, 4, 0, 1\\)\n\\(\\frac{0 + 4 + 0 + 1}{4} = \\frac{5}{4} = 1.25\\)\n\nThis tells us, that on average, our set of predicted values is \\(1.25\\) units off from the actual values.\nIn a nutshell, you take the mean of the square of the differences between the predicted and actual values.\n\nThe main difference between MAE and MSE is that MSE penalizes smaller differences more heavily.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe reason the square value is taken is due to the averaging step. Let’s say the first predicted value is off from the first actual value by \\(-3\\) units. And let’s say that the second predicted value is off from the second actual value by \\(3\\) units.\nIf we didn’t take the square, the average would be zero \\(\\left( \\frac{-3 + 3}{2} = \\frac{0}{2} = 0 \\right)\\). This is incorrect as both values are off from the actual value.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/cross_entropy_loss.html",
    "href": "dictionary/terms/cross_entropy_loss.html",
    "title": "Cross Entropy Loss",
    "section": "",
    "text": "Let’s say that we have a model that tells us what sort of vehicle is in a picture. It outputs the following predictions.\n\n\n\n\n\n\n\n\nVehicle\nActuals\nPrediction\n\n\n\n\ncar\n0\n\\(-4.89\\)\n\n\nbus\n1\n\\(2.60\\)\n\n\ntruck\n0\n\\(0.59\\)\n\n\nmotorbike\n0\n\\(-2.07\\)\n\n\nbicycle\n0\n\\(-4.57\\)\n\n\n\nActuals is a one hot encoded column that tells us what is the correct vehicle in the picture.\nTo convert these predictions into loss, first take the softmax of each prediction.\n\n\n\n\n\n\n\n\n\nVehicle\nActuals\nPrediction\nSoftmax\n\n\n\n\ncar\n0\n\\(-4.89\\)\n\\(4.88 \\cdot 10^{-4}\\)\n\n\nbus\n1\n\\(2.60\\)\n\\(0.874\\)\n\n\ntruck\n0\n\\(0.59\\)\n\\(0.117\\)\n\n\nmotorbike\n0\n\\(-2.07\\)\n\\(8.19 \\cdot 10^{-3}\\)\n\n\nbicycle\n0\n\\(-4.57\\)\n\\(6.72 \\cdot 10^{-4}\\)\n\n\n\nNext take the logarithm of each softmax value.\n\n\n\n\n\n\n\n\n\n\nVehicle\nActuals\nPrediction\nSoftmax\n\\(\\ln(\\text{Softmax})\\)\n\n\n\n\ncar\n0\n\\(-4.89\\)\n\\(4.88 \\cdot 10^{-4}\\)\n\\(-7.63\\)\n\n\nbus\n1\n\\(2.60\\)\n\\(0.874\\)\n\\(-1.35\\)\n\n\ntruck\n0\n\\(0.59\\)\n\\(0.117\\)\n\\(-2.14\\)\n\n\nmotorbike\n0\n\\(-2.07\\)\n\\(8.19 \\cdot 10^{-3}\\)\n\\(-4.81\\)\n\n\nbicycle\n0\n\\(-4.57\\)\n\\(6.72 \\cdot 10^{-4}\\)\n\\(-7.31\\)\n\n\n\nMultiply the actuals with the computed logarithms.\n\n\n\n\n\n\n\n\n\n\n\nVehicle\nActuals\nPrediction\nSoftmax\n\\(\\ln(\\text{Softmax})\\)\n\\(\\text{Actuals} \\cdot \\ln(\\text{Softmax})\\)\n\n\n\n\ncar\n0\n\\(-4.89\\)\n\\(4.88 \\cdot 10^{-4}\\)\n\\(-7.63\\)\n\\(0\\)\n\n\nbus\n1\n\\(2.60\\)\n\\(0.874\\)\n\\(-1.35\\)\n\\(-1.35\\)\n\n\ntruck\n0\n\\(0.59\\)\n\\(0.117\\)\n\\(-2.14\\)\n\\(0\\)\n\n\nmotorbike\n0\n\\(-2.07\\)\n\\(8.19 \\cdot 10^{-3}\\)\n\\(-4.81\\)\n\\(0\\)\n\n\nbicycle\n0\n\\(-4.57\\)\n\\(6.72 \\cdot 10^{-4}\\)\n\\(-7.31\\)\n\\(0\\)\n\n\n\nSum the the results of the multiplications.\n\\[\n0 + -1.35 + 0 + 0 + 0 = -1.35\n\\]\nAnd there you have your loss!\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/optimizer.html",
    "href": "dictionary/terms/optimizer.html",
    "title": "Optimizer",
    "section": "",
    "text": "An optimizer in its most basic form looks like this.\nwith torch.no_grad(): \n  for p in model.parameters(): p -= p.grad * lr \n  model.zero_grad() \n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/softmax.html",
    "href": "dictionary/terms/softmax.html",
    "title": "Softmax",
    "section": "",
    "text": "Let’s say that we have a model that tells us what sort of vehicle is in a picture. It outputs the following predictions.\n\n\n\n\n\n\n\nVehicle\nPrediction\n\n\n\n\ncar\n\\(-4.89\\)\n\n\nbus\n\\(2.60\\)\n\n\ntruck\n\\(0.59\\)\n\n\nmotorbike\n\\(-2.07\\)\n\n\nbicycle\n\\(-4.57\\)\n\n\n\nThese predictions aren’t very meaningful to us as humans. So what we can do is convert these predictions into probabilities. The steps to do this are below.\n1. Take the exponent of each prediction to base \\(e\\). So for the car category, \\(e^{-4.89} \\approx 7.52 \\cdot 10^{-3}\\).\nThe results of the calculations below are displayed with 3 significant figures.\n\n\n\n\n\n\n\n\nVehicle\nPrediction\n\\(e^{\\text{prediction}}\\)\n\n\n\n\ncar\n\\(-4.89\\)\n\\(7.52 \\cdot 10^{-3}\\)\n\n\nbus\n\\(2.60\\)\n\\(13.4\\)\n\n\ntruck\n\\(0.59\\)\n\\(1.80\\)\n\n\nmotorbike\n\\(-2.07\\)\n\\(0.126\\)\n\n\nbicycle\n\\(-4.57\\)\n\\(0.010\\)\n\n\n\n2. Sum all the calculated values.\n\n\n\n\n\n\n\n\n\nVehicle\nPrediction\n\\(e^{\\text{prediction}}\\)\n\\(\\text{sum of} e^{\\text{prediction}}\\)\n\n\n\n\ncar\n\\(-4.89\\)\n\\(7.52 \\cdot 10^{-3}\\)\n\\(15.4\\)\n\n\nbus\n\\(2.60\\)\n\\(13.4\\)\n\\(15.4\\)\n\n\ntruck\n\\(0.59\\)\n\\(1.80\\)\n\\(15.4\\)\n\n\nmotorbike\n\\(-2.07\\)\n\\(0.126\\)\n\\(15.4\\)\n\n\nbicycle\n\\(-4.57\\)\n\\(0.010\\)\n\\(15.4\\)\n\n\n\n3. For each respective category, divide \\(e^{\\text{prediction}}\\) by \\(\\text{sum of} e^{\\text{prediction}}\\). This is your probability. So the probability of the vehicle in the picture being a car is\n\\[\n\\frac{7.52 \\cdot 10^{-3}}{15.4} \\approx 4.88 \\cdot 10^{-4} = 0.000488 = 0.0488 \\%\n\\]\n\n\n\n\n\n\n\n\n\n\nVehicle\nPrediction\n\\(e^{\\text{prediction}}\\)\n\\(\\text{sum of} e^{\\text{prediction}}\\)\n\\(\\frac{e^{\\text{prediction}}}{\\text{sum of}e^{\\text{prediction}}}\\)\n\n\n\n\ncar\n\\(-4.89\\)\n\\(7.52 \\cdot 10^{-3}\\)\n\\(15.4\\)\n\\(4.88 \\cdot 10^{-4}\\)\n\n\nbus\n\\(2.60\\)\n\\(13.4\\)\n\\(15.4\\)\n\\(0.874\\)\n\n\ntruck\n\\(0.59\\)\n\\(1.80\\)\n\\(15.4\\)\n\\(0.117\\)\n\n\nmotorbike\n\\(-2.07\\)\n\\(0.126\\)\n\\(15.4\\)\n\\(8.19 \\cdot 10^{-3}\\)\n\n\nbicycle\n\\(-4.57\\)\n\\(0.010\\)\n\\(15.4\\)\n\\(6.72 \\cdot 10^{-4}\\)\n\n\n\nFrom the table above, it can be seen that the vehicle in the picture is most likely a bus with probability \\(87.4\\%\\).\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/dataset.html",
    "href": "dictionary/terms/dataset.html",
    "title": "Dataset",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/loss.html",
    "href": "dictionary/terms/loss.html",
    "title": "Loss",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/document.html",
    "href": "dictionary/terms/document.html",
    "title": "Document",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/mean_columnwise_root_mean_square_error_mcrmse.html",
    "href": "dictionary/terms/mean_columnwise_root_mean_square_error_mcrmse.html",
    "title": "Mean Columnwise Root Mean Squared Error (MCRMSE)",
    "section": "",
    "text": "Let’s say a model had to predict the velocity, acceleration, and drag force for 3 cars.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/gradient_accumulation.html",
    "href": "dictionary/terms/gradient_accumulation.html",
    "title": "Gradient Accumulation",
    "section": "",
    "text": "Let’s say you want to use a batch size of 64, but the model doesn’t fit with that size on your GPU.\n\nFirst determine the largest possible batch size that can fit on your GPU. Let’s say it’s 16. It may be better to use batch sizes that are a power of 2.\nCalculate the gradients for \\(X\\) batches without updating the parameters.\n\n\\(X\\) is your desired batch size divided by the batch size you are using.\nDesired batch size is 64; batch size we are using is 16.\n\\(64 ÷ 16 = 4\\)\n\\(X\\) is 4. This is because the size of 4 batches, in this case, sums to 64.\n\nNext, sum all respective gradients — hence the term ‘gradient accumulation’.\nNow update your parameters based on these summed gradients. This will have the same effect as if you used a batch size of 64.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nUsing a smaller batch size to fit a larger model onto your GPU isn’t optimal. A smaller batch size means you would have to tweak your optimal hyperparameters, such as the learning rate. Your loss would also become less accurate since it is being calculated on a smaller group of items.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/accuracy.html",
    "href": "dictionary/terms/accuracy.html",
    "title": "Accuracy",
    "section": "",
    "text": "It can be calculated by dividing the number of correct predictions by the number of total predictions. Optionally multiply the result by 100 to obtain a percentage.\n\\[\n\\frac{\\text{number of correct predictions}}{\\text{number of total predictions}}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nAccuracy is also 1 - error rate.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/neuron.html",
    "href": "dictionary/terms/neuron.html",
    "title": "Neuron",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/k_fold_cross_validation.html",
    "href": "dictionary/terms/k_fold_cross_validation.html",
    "title": "K-Fold Cross Validation",
    "section": "",
    "text": "Another way to think of it is that the dataset is split into \\(K\\) pieces. Then each model is trained on a different set of \\(K-1\\) pieces.\nFor example, let’s say that the dataset is split into 5 pieces. Then each model is trained on a different set of 4 pieces.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/architecture.html",
    "href": "dictionary/terms/architecture.html",
    "title": "Architecture",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/root_mean_squared_logarithmic_error_rmsle.html",
    "href": "dictionary/terms/root_mean_squared_logarithmic_error_rmsle.html",
    "title": "Root Mean Squared Logarithmic Error (RMSLE)",
    "section": "",
    "text": "It is calculated by:\n\nFirst taking the logarithm of all predicted values.\nTaking the logarithm of all actual values.\nThen taking the difference between each respective predicted and actual value.\nNext squaring all obtained values.\nTaking the averge.\nAnd lastly taking the square root.\n\nLet’s say we have a set of predicted values \\(1, 2, 3, 4\\). The set of actual values is \\(1, 4, 3, 3\\)\n\n\\(\\ln(1), \\ln(2), \\ln(3), \\ln(4) \\approx 0, 0.69, 1.10, 1.39\\)\n\\(\\ln(1), \\ln(4), \\ln(3), \\ln(3) \\approx 0, 1.39, 1.10, 1.10\\)\n\\(0-0, 0.69-1.39, 1.10-1.10, 1.39-1.10 = 0, -0.70, 0, 0.29\\)\n\\((0)^2, (-0.70)^2, (0)^2, (0.29)^2 \\approx 0, 0.49, 0, 0.08\\)\n\\(\\frac{0 + 0.49 + 0 + 0.08}{4} = \\frac{0.57}{4}\\)\n\\(\\sqrt{\\frac{0.57}{4}} \\approx 0.38\\)\n\nThis tells us, that on average, our set of predicted values is \\(0.38\\) units off from the actual values.\nIn a nutshell, you take the root of the mean of the square of the differences between the predicted and actual values.\n\nThe main difference between RMSE and RMSLE is that RMSLE works better for very large values, since the logarithm of the predicted values and actual values is taken. The downside is that negative values will not work, since the logarithm of a negative value is undefined.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe reason the square value is taken is due to the averaging step. Let’s say the first predicted value is off from the first actual value by \\(-3\\) units. And let’s say that the second predicted value is off from the second actual value by \\(3\\) units.\nIf we didn’t take the square, the average would be zero \\(\\left( \\frac{-3 + 3}{2} = \\frac{0}{2} = 0 \\right)\\). This is incorrect as both values are off from the actual value.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/embedding.html",
    "href": "dictionary/terms/embedding.html",
    "title": "Embedding",
    "section": "",
    "text": "An example of how two embeddings can be combined together is shown below.\nLet’s say we have an embedding of users, where each column represents a feature about movies. Users like certain features of movies, and a value between -1 and 1 represents this.\n\n\n\nUser\nLong Duration\nSci-Fi\nFantasy\nAnimated\nAction\n\n\n\n\nBilly\n-0.9\n0.3\n0.2\n0.8\n0.25\n\n\nBob\n-0.85\n1\n-0.25\n0\n0.75\n\n\nJoe\n0.9\n0.85\n0.95\n0.35\n1\n\n\n\nNow let’s say we have an embedding of movies, where each column represents a feature about movies.\n\n\n\n\n\n\n\n\n\n\n\nMovie\nLong Duration\nSci-Fi\nFantasy\nAnimated\nAction\n\n\n\n\nThe Lord of the Rings\n1\n-1\n1\n-0.5\n1\n\n\nCars\n-0.9\n-1\n0.8\n1\n0\n\n\nInterstellar\n0.75\n1\n0\n0\n0.3\n\n\n\nWe want to find out which movie would be the best for Billy to watch. To do so, let’s take the dot product between Billy and each of the respective movies.\n\n\n\n\n\n\nBilly & The Lord of the Rings\n\n\n\n\n\n\\[\n(-0.9 \\cdot 1) + (0.3 \\cdot -1) + (0.2 \\cdot 1) + (0.8 \\cdot -0.5) + (0.25 \\cdot 1) = -1.15\n\\]\n\n\n\n\n\n\n\n\n\nBilly & Cars\n\n\n\n\n\n\\[\n(-0.9 \\cdot -0.9) + (0.3 \\cdot -1) + (0.2 \\cdot 0.8) + (0.8 \\cdot 1) + (0.25 \\cdot 0) = 1.47\n\\]\n\n\n\n\n\n\n\n\n\nBilly & Interstellar\n\n\n\n\n\n\\[\n(-0.9 \\cdot 0.75) + (0.3 \\cdot 1) + (0.2 \\cdot 0) + (0.8 \\cdot 0) + (0.25 \\cdot 0.3) = -0.3\n\\]\n\n\n\nWe have obtained the values \\(-1.15\\), \\(1.47\\), and \\(-0.3\\) for each of the movies respectively. From this, we can deduce that Cars ($1.47) is probably the best movie for Billy to watch, based on his taste.\nAfter similarly calculating the dot product between Joe and each of the movies, we get the following respective values: \\(1.82\\), \\(-0.55\\), \\(1.82\\). This tells us that both The Lord of the Rings and Interstellar are equally the best movies for Joe to watch.\nAs for Bob, it would be Interstellar.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/dot_product.html",
    "href": "dictionary/terms/dot_product.html",
    "title": "Dot Product",
    "section": "",
    "text": "\\[\n\\begin{bmatrix}\n1 \\\\\n2 \\\\\n3 \\\\\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n4 \\\\\n5 \\\\\n6 \\\\\n\\end{bmatrix}\n= (1 \\cdot 4) + (2 \\cdot 5) + (3 \\cdot 6) = 32\n\\]\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/latent.html",
    "href": "dictionary/terms/latent.html",
    "title": "Latent (Diffusion)",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/one_hot_encoding.html",
    "href": "dictionary/terms/one_hot_encoding.html",
    "title": "One Hot Encoding",
    "section": "",
    "text": "Let’s say we have a categorical feature, speed, that can be either slow or fast. Instead of assigning a value of 0 to slow and a value of 1 to fast, a slow column can be created and a fast column can be created. If the speed is slow, slow is true and fast is false. If the speed is fast, slow is false and fast is true.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/rectified_linear_unit.html",
    "href": "dictionary/terms/rectified_linear_unit.html",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/transformer.html",
    "href": "dictionary/terms/transformer.html",
    "title": "Transformer",
    "section": "",
    "text": "To learn more about transformers, you can read this to the point rundown.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/backpropagation.html",
    "href": "dictionary/terms/backpropagation.html",
    "title": "Backpropagation",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/learning_rate.html",
    "href": "dictionary/terms/learning_rate.html",
    "title": "Learning Rate",
    "section": "",
    "text": "The learning rate controls how much the gradients adjust the parameters by multiplying the learning rate and gradients together.\n\n\n\n\n\n\nNote\n\n\n\n\n\nA learning rate that is too high can cause the training system to either get stuck in a loop or diverge from the optimal weights.\nA learning rate that is too low can cause the training system to take a very long time to reach the optimal weights.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/dataloader.html",
    "href": "dictionary/terms/dataloader.html",
    "title": "Dataloader",
    "section": "",
    "text": "Metaphorically speaking, if we let a dataset be a warehouse, a dataloader be a human, a batch be a crate, and the sampler be the manager, then the manager is responsible for informing the human what items to gather from the warehouse, who then puts them into crates.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/random_forest.html",
    "href": "dictionary/terms/random_forest.html",
    "title": "Random Forest",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/sample.html",
    "href": "dictionary/terms/sample.html",
    "title": "Sample",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/mean_absolute_error_mae.html",
    "href": "dictionary/terms/mean_absolute_error_mae.html",
    "title": "Mean Absolute Error (MAE)",
    "section": "",
    "text": "It is calculated by: 1. First taking the difference between each respective predicted and actual value. 1. Then removing all negative signs — this is known as taking the absolute value. 1. And finally taking the average.\nLet’s say we have a set of predicted values \\(1, 2, 3, 4\\). The set of actual values is \\(1, 4, 3, 3\\)\n\n\\(1-1, 2-4, 3-3, 4-3, = 0, -2, 0, 1\\)\n\\(|0|, |-2|, |0|, |1| = 0, 2, 0, 1\\)\n\\(\\frac{0 + 2 + 0 + 1}{4} = \\frac{2}{4} = 0.5\\)\n\nThis tells us, that on average, our set of predicted values is \\(0.5\\) units off from the actual values.\nIn a nutshell, you take the mean of the absolute differences between the predicted and actual values.\n\nThe main difference between MAE and MSE is that MSE penalizes smaller differences more heavily.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe reason the absolute value is taken is due to the averaging step. Let’s say the first predicted value is off from the first actual value by \\(-3\\) units. And let’s say that the second predicted value is off from the second actual value by \\(3\\) units.\nIf we didn’t take the absolute value, the average would be zero \\(\\left( \\frac{-3 + 3}{2} = \\frac{0}{2} = 0 \\right)\\). This is incorrect as both values are off from the actual value.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/zero_shot.html",
    "href": "dictionary/terms/zero_shot.html",
    "title": "Zero-shot",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "testing_page.html",
    "href": "testing_page.html",
    "title": "Testing Page",
    "section": "",
    "text": "Trying to change Quarto Version.\n\n\nForBlog\n\n\n\n\n\n\n\n\n\n\nIntroduction to Deep Neural Networks: Mathematical Foundations and Architectures\n\n\n\n\n\nMathematical foundations of deep learning with focus on Physics-Informed Neural Networks\n\n\n\n\n\nAntonio O.R.\n\n\n\n\n\n\nNo matching items\n\n\n\n\nPlayground\n\n\n\n\n\n\n\n\n\n\nMore apps coming soon…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlood Classifier\n\n\nHow well can you classify floods?\n\n\n\nSalman Naqvi\n\n\nSep 20, 2022\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "unsubscribe.html",
    "href": "unsubscribe.html",
    "title": "Unsubscribe from ForBlog and App Playground Notifications",
    "section": "",
    "text": "Loading…\n\n\n\n\n Back to top"
  },
  {
    "objectID": "forblog/index.html",
    "href": "forblog/index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nIntroduction to Deep Neural Networks: Mathematical Foundations and Architectures\n\n\n\n\n\nMathematical foundations of deep learning with focus on Physics-Informed Neural Networks\n\n\n\n\n\nAntonio O.R.\n\n\n9 min\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "feedback.html",
    "href": "feedback.html",
    "title": "Site Feedback",
    "section": "",
    "text": "Loading…"
  },
  {
    "objectID": "web_apps/index.html",
    "href": "web_apps/index.html",
    "title": "App Playground",
    "section": "",
    "text": "Here you can view various apps and gizmos I’ve created. Have a play through some of them let me know what you think!\nMore apps coming soon.™\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nMore apps coming soon…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlood Classifier\n\n\n\nImage Classification\n\n\n\nHow well can you classify floods?\n\n\n\nSalman Naqvi\n\n\nTuesday, 20 September 2022 | 2022-09-20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBear Classifier\n\n\n\nImage Classification\n\n\n\nCan you spot a black bear in a black night?\n\n\n\nSalman Naqvi\n\n\nSaturday, 30 April 2022 | 2022-04-30\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\nLoading…"
  },
  {
    "objectID": "web_apps/apps/bear_detector.html",
    "href": "web_apps/apps/bear_detector.html",
    "title": "Bear Classifier",
    "section": "",
    "text": "This webapp was remade on Tuesday, 8 November 2022.\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/posts/2025-01-27-A.html",
    "href": "bitsandbobs/posts/2025-01-27-A.html",
    "title": "不 vs 没",
    "section": "",
    "text": "In a nutshell.\n不: - Negates present and future - Negates habitual actions and adjectives\n没: - Negates past - Negates something that hasn’t happened\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/posts/2025-02-13-A.html",
    "href": "bitsandbobs/posts/2025-02-13-A.html",
    "title": "Deepseek R1 in 2 bullets",
    "section": "",
    "text": "Am currently reading through the research paper. From my current understanding:\n\nR1-Zero is pure RL, with GRPO as the policy\nR1 is unpure RL, with GRPO as the policy, with some SFT in the form of cold start data, and further refinement stages\n\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/posts/2025-01-21-A.html",
    "href": "bitsandbobs/posts/2025-01-21-A.html",
    "title": "OmniManip: Towards General Robotic Manipulation via Object-Centric Interaction Primitives as Spatial Constraints",
    "section": "",
    "text": "OmniManip is a hot new paper from Agibot and Peking University. It’s about zero shot natural language robotic manipulation tasks. A current issue with this task, and current approaches the utilize VLMs, is that VLMs lack 3D spatial understanding. They’re only trained on 2D images and video after all.\nOmniManip utilizes an ensemble of models to achieve this goal. This is how it works at a high level.\nA segmentation model is used to extract relevant objects from the robot’s vision. A VLM then filters out task relevant objects, and also breaks down the input task (input as text) into multiple stages.\nNext, for each stage of the task, interaction primitives and their spatial constraints are extracted. A single view 3D generation model is used to generate meshes for all objects relevant to the task. A pose estimation model is then used to canonicalize the objects. Interaction primitives and their corresponding constraints relevant for the task are then identified by the VLM. Along the way, a LLM is used to grade various primitives and constriants.\nModels hallucinate (in particular, the VLM). The world is not static. To overcome this, a closed loop system is introduced; a self correction mechanism based on resampling, rendering and checking. This method uses realtime feedback form the VLM, which is used to detect and then correct interaction errors. A pose tracking algorithm is also used to continuously update the poses of all relevant objects, allowing the robot to be dynamically adjusted.\nLink to paper.\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/posts/2025-01-14-A.html",
    "href": "bitsandbobs/posts/2025-01-14-A.html",
    "title": "小和年轻",
    "section": "",
    "text": "小 can indicate whether one is young or old. For example, 她有一个小孩儿. However, you have to be careful when using 年轻, as it carries the connotation of being the opposite of old. If you’re saying you’re younger than someone, and you use 年轻, it also implies that the other person is old. 小 does not carry this connotation.\nFrom the Chinese Grammar Wiki (including the example sentence)..\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/index.html",
    "href": "bitsandbobs/index.html",
    "title": "Academic Works",
    "section": "",
    "text": "2024\n\n\n\n Bachelor’s Thesis\n\nDetection of Machine Translation Through Distributional Text Properties\nUniversity of Alicante · 2024 · [PDF available upon request]\nAbstract:\nThis work develops automated methods to distinguish between human and machine-translated texts by analyzing linguistic patterns. The key components include:\n\nAnalysis of Beam Search algorithm limitations in machine translation\n\nFeature engineering using lexical diversity metrics and TF-IDF statistics\n\nComparative evaluation of logistic regression vs. tree-based models (CART, Random Forest)\n\nCross-domain testing with parallel corpora of varying lengths and topics\n\nKey Finding: Logistic regression using TF-IDF features achieved superior performance in detecting machine-translated content, particularly when trained on diverse text lengths and domains.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/posts/2025-01-02-A.html",
    "href": "bitsandbobs/posts/2025-01-02-A.html",
    "title": "没几个",
    "section": "",
    "text": "没几个 is a way of saying a “very few” of something, rather than “not few”.\n我认识的人很多，但没几个好朋友。\nFrom the Immersive Chinese App.\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/posts/2025-01-28-A.html",
    "href": "bitsandbobs/posts/2025-01-28-A.html",
    "title": "Robo-ABC: Affordance Generalization Beyond Categories via Semantic Correspondence for Robot Manipulation",
    "section": "",
    "text": "DenseMatcher is a method for generalization the “understanding” of one object to another. The best way to understand this, is to view the following images from the paper.\n\n\nIn other words, DenseMatcher computes 3D correspondences between objects.\nIt works by using SD-DINO (a combination of Stable Diffusion and DINO) to extract 2D features from different angles of the 3D asset. The features from different views are averaged, providing the feature for each vertex.\n\nHowever, as seen in the image above, the features are noisy. Therefore, the features are then refined with DiffusionNet. This is an architecture meant for meshes.\n\nAfter the features have been refined, a functional map is solved to compute correspondences.\n\nLink to paper. All images in this post are from the paper.\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/posts/2025-01-23-A.html",
    "href": "bitsandbobs/posts/2025-01-23-A.html",
    "title": "Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces",
    "section": "",
    "text": "This paper tackles the issue that is the lack of spatial understanding and spatial reasoning that MLLM/VLMs.\nIn this paper, the authors created a benchmark for spatial reasoning, consisting of over 5000 QnA pairs from 288 indoor videos. A variety of tasks are covered, including configurational (e.g,. object count, route planning), measurement estimation (e.g., room size), and spatiotempral reasoning (e.g., appearance order). 79% accuracy on the benchmark is needed to reach human level awareness. The authors found that their MLLM could only reach 49%.\nThe resulting analysis from the paper shows that 71% of errors stem from spatial reasoning, rather than perception or language understanding. By generating spatial layout (cognitive maps), accuracy on distance related tasks improved by 10%. This outperforms linguistic prompting techniques such as CoT. In fact, CoT degraded performance on the benchmark.\nIt was also found that MLLMs have strong local spatial awareness, but struggle with global awareness.\nWeaknesses in the study include reliance on 3D datasets that may contain annotation errors, video processing and langauge model evaluation being resource intensive, and the study focusing on indoor scenes and not outdoor scenes.\nFuture directions encourage research into hybrid models that are both language and spatial memory, self-supervised objectives for spatial learning, and fine-tuning for VSI tasks.\nLink to paper.\n\n\n\n\n\n\nDeepseek R1 Summary\n\n\n\n\n\nStructured Summary of “Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces”\n\nContextual Overview\n\nResearch Question: Can Multimodal Large Language Models (MLLMs) exhibit human-like visual-spatial intelligence (VSI) when reasoning about 3D spaces from videos?\n\nObjective: Develop a benchmark (VSI-Bench) to evaluate MLLMs’ ability to perceive, remember, and reason about spatial relationships in real-world indoor environments.\n\nDomain: Multimodal AI, spatial reasoning, video understanding.\n\nMotivation: Visual-spatial intelligence is critical for robotics, AR/VR, and autonomous systems, but existing MLLM benchmarks focus on 2D image/text understanding. This work addresses the gap in evaluating 3D spatial reasoning from video input.\n\n\n\n\nKey Contributions\n\nVSI-Bench: A novel benchmark with 5,000+ QA pairs derived from 288 real indoor videos (from ScanNet, ScanNet++, ARKitScenes). Tasks include configurational (e.g., object count, route planning), measurement estimation (e.g., room size), and spatiotemporal reasoning (e.g., appearance order).\n\nSpatial Reasoning as Bottleneck: Analysis shows 71% of errors stem from spatial reasoning (e.g., egocentric-allocentric transformations), not perception or language understanding.\n\nCognitive Maps Enhance Performance: Explicitly generating spatial layouts (cognitive maps) improves MLLMs’ accuracy on relative distance tasks by 10%, outperforming linguistic prompting techniques like Chain-of-Thought.\n\nFailure of Linguistic Reasoning: Prevailing methods (CoT, self-consistency, Tree-of-Thoughts) degraded performance on VSI-Bench, highlighting the distinct challenges of spatial reasoning.\n\nLocal vs. Global Spatial Models: MLLMs build strong local spatial awareness (64% accuracy for adjacent objects) but struggle with global consistency.\n\n\n\n\nMethodology Deep Dive\n\nData/Resources:\n\nVideos from ScanNet (24 FPS), ScanNet++, ARKitScenes (30 FPS), standardized to 640×480 resolution.\n\nQA pairs auto-generated using templates and human annotation (for route planning).\n\n\nCore Techniques:\n\nUnified Meta-Information: Structured annotations for object counts, bounding boxes, room size, and spatial relationships.\n\nEvaluation Metrics: Accuracy (for multiple-choice), Mean Relative Accuracy (for numerical answers).\n\nCognitive Map Generation: Prompting MLLMs to output object positions on a 10×10 grid.\n\n\nValidation:\n\n15 MLLMs tested, including GPT-4o, Gemini-1.5 Pro, and open-source models (LLaVA variants).\n\nHuman baseline: 79% accuracy vs. Gemini-1.5 Pro (45.4%).\n\nBlind evaluation confirmed video input is critical (performance drops to chance level without it).\n\n\n\n\n\nStrengths and Weaknesses\n\nStrengths:\n\nComprehensive Benchmark: High-quality, diverse tasks with iterative human review.\n\nNovel Insights: Identifies spatial reasoning as the key bottleneck and demonstrates cognitive maps’ utility.\n\nReproducibility: Public code, metrics, and standardized evaluation protocols.\n\n\nWeaknesses:\n\nDataset Bias: Relies on existing 3D datasets, which may inherit annotation errors.\n\nCompute Demands: Video processing and large model evaluation are resource-intensive.\n\nLimited Generalization: Focus on indoor scenes; outdoor/embodied settings unexplored.\n\n\n\n\n\nRelevance to the Field\n\nAdvances: Establishes a foundation for evaluating and improving MLLMs’ spatial reasoning, crucial for embodied AI (e.g., robots, autonomous navigation).\n\nContrast with Prior Work: Unlike image-based or text-only spatial benchmarks, VSI-Bench uses video to mirror real-world observation.\n\nFuture Directions: Encourages research into hybrid models (language + spatial memory), self-supervised objectives for spatial learning, and fine-tuning for VSI tasks.\n\n\n\n\nKey Takeaways\n\nMLLMs lag behind humans in visual-spatial intelligence (45% vs. 79% accuracy) but show emerging capabilities.\n\nSpatial reasoning—not perception or language—is the primary challenge for MLLMs.\n\nCognitive maps improve spatial reasoning, suggesting a path toward better world modeling.\n\nLinguistic prompting (CoT, etc.) fails for spatial tasks, demanding new techniques tailored to visuospatial reasoning.\n\nLocal spatial awareness exists in MLLMs, but global consistency remains elusive.\n\n\nNon-Technical Insights for Decision-Makers:\n- VSI-Bench is a critical tool for developers aiming to build MLLMs for real-world navigation or AR/VR.\n- Spatial reasoning enhancements (e.g., cognitive maps) could bridge the gap between MLLMs and human-like spatial understanding.\n- Open-source models (e.g., LLaVA-NeXT-Video-72B) are competitive with closed-source counterparts, offering cost-effective alternatives.\nLet me know if you’d like to dive deeper into specific sections!\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "bitsandbobs/posts/2025-02-18-A.html",
    "href": "bitsandbobs/posts/2025-02-18-A.html",
    "title": "Seeking Deep Thoughts",
    "section": "",
    "text": "I started reading the Deepseek Math paper, after recently finishing the R1 paper. The following thoughts started coming to mind:\n\nR1 is successful simply because of the training process\nDeepseek Math is worked really well because of data quality\nGRPO is used only to reduce memory usage (still reading the Deepseek Math paper; I could be wrong)\n\nTakeaway is that a lot can be done by simply flipping and rearranging all the existing levers and switches we already have.\n\n\n\n Back to top"
  },
  {
    "objectID": "web_apps/apps/flood_detector.html",
    "href": "web_apps/apps/flood_detector.html",
    "title": "Flood Classifier",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "web_apps/apps/coming_soon.html",
    "href": "web_apps/apps/coming_soon.html",
    "title": "More apps coming soon…",
    "section": "",
    "text": "I never told you how soon…\n\n\n\nThis image was generated by Dall-E 2!\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "patch_notes.html",
    "href": "patch_notes.html",
    "title": "Site Patch Notes",
    "section": "",
    "text": "Detailed patch notes are unavailable prior to site version 2.0.0.0."
  },
  {
    "objectID": "patch_notes.html#version-2.2.2.0-28-december-2024",
    "href": "patch_notes.html#version-2.2.2.0-28-december-2024",
    "title": "Site Patch Notes",
    "section": "Version 2.2.2.0 | 28 December 2024",
    "text": "Version 2.2.2.0 | 28 December 2024\n\nLaunched Bits and Bobs.\nUnlinked App Playground.\nReplaced App Playground with Bits and Bobs on landing page."
  },
  {
    "objectID": "patch_notes.html#version-2.2.1.6-27-december-2024",
    "href": "patch_notes.html#version-2.2.1.6-27-december-2024",
    "title": "Site Patch Notes",
    "section": "Version 2.2.1.6 | 27 December 2024",
    "text": "Version 2.2.1.6 | 27 December 2024\n\nUpdated copyright notices for 2025 and beyond."
  },
  {
    "objectID": "patch_notes.html#version-2.2.2.0-26-may-2024",
    "href": "patch_notes.html#version-2.2.2.0-26-may-2024",
    "title": "Site Patch Notes",
    "section": "Version 2.2.2.0 | 26 May 2024",
    "text": "Version 2.2.2.0 | 26 May 2024\n\nRemoved buttons.\nTweaked footer text."
  },
  {
    "objectID": "patch_notes.html#version-2.2.1.4-23-may-2024",
    "href": "patch_notes.html#version-2.2.1.4-23-may-2024",
    "title": "Site Patch Notes",
    "section": "Version 2.2.1.4 | 23 May 2024",
    "text": "Version 2.2.1.4 | 23 May 2024\n\nFixed Mermaid diagram rendering issue."
  },
  {
    "objectID": "patch_notes.html#version-2.2.1.3-1-january-2024",
    "href": "patch_notes.html#version-2.2.1.3-1-january-2024",
    "title": "Site Patch Notes",
    "section": "Version 2.2.1.3 | 1 January 2024",
    "text": "Version 2.2.1.3 | 1 January 2024\n\nUpdated copyright notices for 2024."
  },
  {
    "objectID": "patch_notes.html#version-2.2.1.2-3-august-2023",
    "href": "patch_notes.html#version-2.2.1.2-3-august-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.2.1.2 | 3 August 2023",
    "text": "Version 2.2.1.2 | 3 August 2023\n\nRemoved featured posts section in the ForBlog."
  },
  {
    "objectID": "patch_notes.html#version-2.2.1.1-1-august-2023",
    "href": "patch_notes.html#version-2.2.1.1-1-august-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.2.1.1 | 1 August 2023",
    "text": "Version 2.2.1.1 | 1 August 2023\n\nSplit website footer into 3 sections."
  },
  {
    "objectID": "patch_notes.html#version-2.2.1.0-31-july-2023",
    "href": "patch_notes.html#version-2.2.1.0-31-july-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.2.1.0 | 31 July 2023",
    "text": "Version 2.2.1.0 | 31 July 2023\n\nAdded a featured posts section in the ForBlog.\nIncreased thumbnail size in the App Playground.\nFixed Ship of Theseus link in patch notes."
  },
  {
    "objectID": "patch_notes.html#version-2.2.0.2-15-july-2023",
    "href": "patch_notes.html#version-2.2.0.2-15-july-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.2.0.2 | 15 July 2023",
    "text": "Version 2.2.0.2 | 15 July 2023\n\nRe-enabled App Playground."
  },
  {
    "objectID": "patch_notes.html#version-2.2.0.1-13-may-2023",
    "href": "patch_notes.html#version-2.2.0.1-13-may-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.2.0.1 | 13 May 2023",
    "text": "Version 2.2.0.1 | 13 May 2023\n\nFixed animations for the App Playground.\nFixed back-to-top button covering content on the About Me page."
  },
  {
    "objectID": "patch_notes.html#version-2.2.0.0-13-may-2023",
    "href": "patch_notes.html#version-2.2.0.0-13-may-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.2.0.0 | 13 May 2023",
    "text": "Version 2.2.0.0 | 13 May 2023\n\nImplemented site-wide animations!\nConsolidated unsubscribe form and all subscribe forms into a single form.\nAdded a back-to-top button.\nRSS and source code navbar icons are now positioned more cleanly when accessed from the drop down menu on smaller screens.\nIncreased number of displayed posts on the ForBlog from 5 per page to 7 per page.\nChanged Home navbar icon.\nTemporarily disabled App Playground."
  },
  {
    "objectID": "patch_notes.html#version-2.1.0.1-25-march-2023",
    "href": "patch_notes.html#version-2.1.0.1-25-march-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.1.0.1 | 25 March 2023",
    "text": "Version 2.1.0.1 | 25 March 2023\n\nTweaked the various subscription forms’ positioning."
  },
  {
    "objectID": "patch_notes.html#version-2.1.0.0-23-february-2023",
    "href": "patch_notes.html#version-2.1.0.0-23-february-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.1.0.0 | 23 February 2023",
    "text": "Version 2.1.0.0 | 23 February 2023\n\nLaunched the AI dictionary.\nShortened navbar text."
  },
  {
    "objectID": "patch_notes.html#version-2.0.3.2-22-february-2023",
    "href": "patch_notes.html#version-2.0.3.2-22-february-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.0.3.2 | 22 February 2023",
    "text": "Version 2.0.3.2 | 22 February 2023\n\nUpdated copyright notices for 2023."
  },
  {
    "objectID": "patch_notes.html#version-2.0.3.1-28-january-2023",
    "href": "patch_notes.html#version-2.0.3.1-28-january-2023",
    "title": "Site Patch Notes",
    "section": "Version 2.0.3.1 | 28 January 2023",
    "text": "Version 2.0.3.1 | 28 January 2023\n\nChanged comment section theme."
  },
  {
    "objectID": "patch_notes.html#version-2.0.3.0-27-november-2022",
    "href": "patch_notes.html#version-2.0.3.0-27-november-2022",
    "title": "Site Patch Notes",
    "section": "Version 2.0.3.0 | 27 November 2022",
    "text": "Version 2.0.3.0 | 27 November 2022\n\nFully implemented Twitter Cards."
  },
  {
    "objectID": "patch_notes.html#version-2.0.2.0-26-november-2022",
    "href": "patch_notes.html#version-2.0.2.0-26-november-2022",
    "title": "Site Patch Notes",
    "section": "Version 2.0.2.0 | 26 November 2022",
    "text": "Version 2.0.2.0 | 26 November 2022\n\nFully implemented Open Graph.\nAdded button for direct link to site’s source code.\nTweaked landing page description."
  },
  {
    "objectID": "patch_notes.html#version-2.0.1.2-17-november-2022",
    "href": "patch_notes.html#version-2.0.1.2-17-november-2022",
    "title": "Site Patch Notes",
    "section": "Version 2.0.1.2 | 17 November 2022",
    "text": "Version 2.0.1.2 | 17 November 2022\n\nFixed broken license link."
  },
  {
    "objectID": "patch_notes.html#version-2.0.1.1-17-november-2022",
    "href": "patch_notes.html#version-2.0.1.1-17-november-2022",
    "title": "Site Patch Notes",
    "section": "Version 2.0.1.1 | 17 November 2022",
    "text": "Version 2.0.1.1 | 17 November 2022\n\nFixed broken site feedback link.\nUpdated site version references."
  },
  {
    "objectID": "patch_notes.html#version-2.0.1.0-17-november-2022",
    "href": "patch_notes.html#version-2.0.1.0-17-november-2022",
    "title": "Site Patch Notes",
    "section": "Version 2.0.1.0 | 17 November 2022",
    "text": "Version 2.0.1.0 | 17 November 2022\n\nFixed a bunch of broken links.\nFixed RSS buttons.\nShifted links on the landing page."
  },
  {
    "objectID": "patch_notes.html#version-2.0.0.0-16-november-2022",
    "href": "patch_notes.html#version-2.0.0.0-16-november-2022",
    "title": "Site Patch Notes",
    "section": "Version 2.0.0.0 | 16 November 2022",
    "text": "Version 2.0.0.0 | 16 November 2022\n\nCreated, erm, site patch notes.\nSite is now entirely remade in Quarto.\nUI overhaul.\nForBlog is no longer the main landing page.\nApp playground has been added; a place where I can host my various creations.\n\nNew…\n\nfavicon.\nabout me page.\nlanding page.\nForBlog home page.\nForBlog post layout.\nglobal search bar.\n\nAdded…\n\na ForBlog only search bar.\nForBlog post filters.\nForBlog and App Playground subscriptions.\na form for site feedback.\ncopyright licences.\nnew fancy buttons."
  },
  {
    "objectID": "patch_notes.html#version-1.0.0.0-15-may-2022",
    "href": "patch_notes.html#version-1.0.0.0-15-may-2022",
    "title": "Site Patch Notes",
    "section": "Version 1.0.0.0 | 15 May 2022",
    "text": "Version 1.0.0.0 | 15 May 2022\n\nInitial release.\nSite is built on fastpages, by fastai."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Antonio Ortiz Romero",
    "section": "",
    "text": "I am a mathematics graduate currently employed under the Momentum program at CSIC. My work focuses on developing AI-based tools for the real-time management and optimization of deep geothermal resources. Previously, I completed a 9-month internship at DXC Technology, where I gained experience in data engineering by implementing an ETL pipeline and integrating OpenAI’s API.\n\n\n\nResearch ExperienceLanguagesEducationInternshipsTechnical Skills\n\n\nTitulado Superior FC- Momentum Program | December 2024 - Present (Contract until 2028)\nInstitute of Environmental Assessment and Water Research- IDAEA\n\nDeveloping physics-informed deep learning algorithms for the management and optimization of deep geothermal resources.\nPart of the Porous Media Multiscale Modeling Laboratory (PM3Lab) at IDAEA.\nCombining AI and physics-based modeling to improve real-time decision-making in geothermal systems.\nPlanning to complete a Master’s in Artificial Intelligence as a foundation for a future PhD in the field.\n\n\n\nEnglish: B2 level (CEFR) - Professional working proficiency\nSpanish: Native\n\n\nBachelor in Mathematics | University of Alicante — Sep 2019 – July 2024\n\nBachelor’s Thesis: Detection of Automatic Translation through Distributional Properties of Text\n\nDeveloped binary classifier for machine translation detection\nImplemented word frequency distribution features\nConducted domain/length impact analysis\n\n\n\n\nAI Developer Intern | July 2024 - August 2024\nDXC Technology Company\n\nDeveloped an NLP model using the OpenAI API to assess clarity in formal documents\nFocused on text analysis and natural language processing to improve document readability\nApplied AI techniques to enhance compliance and accessibility in legal and business documents\nGained practical experience in AI development through an internship contract\n\nData Engineer Intern | November 2023 - June 2024\nDXC Technology Company\n\nDesigned and developed an ETL system using T-SQL and PySpark in Microsoft Fabric\nTransformed Excel files containing business opportunities into a dimensional database\nBuilt interactive Power BI reports, improving data quality and facilitating decision-making\nGained hands-on experience in data engineering through an internship contract\n\n\n\nLanguages\nPython (Advanced), SQL, LaTeX, Quarto\nTools\nPySpark, NumPy, Jupyter, Scikit-Learn, PyTorch, Pandas, Power BI, OpenAI API\nMethodologies\nETL, NLP, Deep Learning\n \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "forblog/posts/index.html",
    "href": "forblog/posts/index.html",
    "title": "Introduction to Deep Neural Networks: Mathematical Foundations and Architectures",
    "section": "",
    "text": "Let \\(\\text{x}=(x_1,...,x_n)\\in \\mathbb{R}^n\\) be a multivariate input and \\(\\text{y}=(y_1,...,y_m)\\in \\mathbb{R}^m\\) a multivariate output \\((n,m&gt;0)\\). Shallow neural networks are functions with parameters\n\\[\\begin{align*}\n\\phi=\\{\\phi_{10},...,\\phi_{1d},..., \\phi_{m0},...,\\phi_{md},\\theta_{10},..., \\theta_{d0},...,\\theta_{1n},..., \\theta_{dn}\\},\n\\end{align*}\\]\nwhere \\(d\\) is the number of activation functions a[•].\nCase \\(n=m=1, d=3\\):\n\\[\\begin{align*}\ny &= f[x, \\boldsymbol{\\phi}] \\\\\n  &= \\phi_0 + \\phi_1 a [\\theta_{10} + \\theta_{11} x] + \\phi_2 a [\\theta_{20} + \\theta_{21} x] + \\phi_3 a [\\theta_{30} + \\theta_{31} x].\n\\end{align*}\\]\n\nWe can break down this calculation into three parts:\n\nCompute three linear functions of the input data \\((\\theta_{10} + \\theta_{11} x, \\theta_{20} + \\theta_{21} x, \\theta_{30} + \\theta_{31} x)\\)\nPass the three results through an activation function a[•]\nWeight the three resulting activations with \\(\\theta_1\\) , \\(\\theta_2\\) , and \\(\\theta_3\\) , sum them, and add an offset \\(\\theta_0\\).\n\nTo complete the description, we must define the activation function a[•]. There are many possibilities, but the hyperbolic tangent function is commonly used as an activation function in Physics-Informed Neural Networks (PINNs) due to its smooth and differentiable nature.\n\\[\\begin{align*}\na[z] &= \\tanh[z] =\n\\begin{cases}\n-1 & z \\ll 0 \\\\\nz & |z| \\approx 0 \\\\\n1 & z \\gg 0\n\\end{cases}\n\\end{align*}\\]\nSome advantages of using \\(\\tanh\\) in PINNs include:\n\nSmoothness: Unlike ReLU, \\(\\tanh\\) is infinitely differentiable, which is beneficial for enforcing physical constraints that involve higher-order derivatives.\nSymmetry: It is symmetric around the origin, making it useful for capturing variations in both positive and negative directions.\nBetter Gradient Flow: Compared to sigmoid, \\(\\tanh\\) has a steeper gradient, reducing the risk of vanishing gradients in deep networks.\nPhysical Interpretability: In many physical systems, solutions naturally exhibit smooth transitions, which \\(\\tanh\\) can better approximate.\n\n\n\n\n\n\n\nMetacognitive Insight\n\n\n\n\n\nThis section masterfully bridges theoretical foundations (parameterized functions) with practical considerations (activation function selection), demonstrating how mathematical abstraction serves applied goals. The deliberate decomposition and domain-aware justification reveal expert knowledge organization - transforming complex concepts into teachable components while maintaining scientific rigor."
  },
  {
    "objectID": "forblog/posts/index.html#shallow-vs.-deep-neural-networks",
    "href": "forblog/posts/index.html#shallow-vs.-deep-neural-networks",
    "title": "Introduction to Deep Neural Networks: Mathematical Foundations and Architectures",
    "section": "Shallow vs. deep neural networks",
    "text": "Shallow vs. deep neural networks\n\nAdvantages of Deep Neural Networks for PINNs\nPhysics-Informed Neural Networks (PINNs) benefit significantly from deep architectures due to the following advantages:\n\nSuperior Function Approximation\n\nDeep networks can approximate complex physical functions by leveraging their ability to represent compositions of simpler functions.\n\nThis hierarchical representation aligns well with the multi-scale nature of many physical processes.\n\n\n\nHigher Expressiveness with Fewer Parameters\n\nDeep networks create significantly more linear regions than shallow networks with the same parameter count.\n\nThis allows PINNs to capture intricate solution structures more efficiently.\n\nThe increased expressiveness is particularly useful for solving PDEs with sharp gradients or discontinuities.\n\n\n\nDepth Efficiency in Learning Complex Physics\n\nSome physical problems require exponentially more neurons in a shallow network to match the performance of a deep network.\n\nDeep architectures can learn structured physical relationships with fewer hidden units, making training more efficient.\n\n\n\nHandling High-Dimensional and Structured Inputs\n\nMany physical problems involve high-dimensional inputs (e.g., spatiotemporal fields).\n\nDeep networks can efficiently process local information and integrate it into a global understanding, mimicking numerical solvers.\n\nThis property is crucial when solving PDEs over complex domains, as deep networks can better capture spatial correlations.\n\n\n\n\n\n\n\n\nMetacognitive Insight\n\n\n\n\n\nThe deep neural network formulation demonstrates expert-level knowledge organization by: (1) systematically decomposing hierarchical transformations through layer-wise notation, (2) explicitly tracking parameter dimensions to reinforce computational intuition, and (3) contrasting architectures to highlight inductive biases. The PINN-specific advantages reveal deep domain awareness - connecting abstract network properties to concrete physical modeling requirements through multi-scale reasoning and parameter efficiency arguments."
  },
  {
    "objectID": "forblog/posts/index.html#how-a-model-fmathbfx-phi-can-be-adapted-to-compute-a-probability-distribution",
    "href": "forblog/posts/index.html#how-a-model-fmathbfx-phi-can-be-adapted-to-compute-a-probability-distribution",
    "title": "Introduction to Deep Neural Networks: Mathematical Foundations and Architectures",
    "section": "3.1. How a model \\(f[\\mathbf{x}, \\phi]\\) can be adapted to compute a probability distribution?",
    "text": "3.1. How a model \\(f[\\mathbf{x}, \\phi]\\) can be adapted to compute a probability distribution?\n\nChoose a parametric distribution \\(P(\\mathbf{y}|\\theta)\\) defined on the output domain y,\nUse the network to compute one or more of the parameters \\(\\theta\\) of this distribution.\n\nFor example, suppose the prediction domain is the set of real numbers, so \\(y\\in\\mathbb{R}\\). Here, we might choose the univariate normal distribution, which is defined on \\(\\mathbb{R}\\). This distribution is defined by the mean µ and variance \\(\\sigma^2\\) , so \\(\\theta = \\{\\mu, \\sigma^2\\}\\). The machine learning model might predict the mean \\(\\mu\\), and the variance \\(\\sigma^2\\) could be treated as an unknown constant."
  },
  {
    "objectID": "forblog/posts/index.html#maximum-likelihood-criterion",
    "href": "forblog/posts/index.html#maximum-likelihood-criterion",
    "title": "Introduction to Deep Neural Networks: Mathematical Foundations and Architectures",
    "section": "3. 2. Maximum likelihood criterion",
    "text": "3. 2. Maximum likelihood criterion\nThe model now computes different distribution parameters $ _i = f[x_i , ]$ for each training input \\(x_i\\) . Each observed training output \\(y_i\\) should have high probability under its corresponding distribution \\(P(y_i |\\theta_i )\\). Hence, we choose the model parameters \\(\\phi\\) so that they maximize the combined probability across all \\(I\\) training examples:\n\\[\\begin{align*}\n\\hat{\\boldsymbol{\\phi}} &= \\underset{\\boldsymbol{\\phi}}{\\mathrm{argmax}}\\left[\\prod_{i=1}^I P(y_i|x_i)\\right]\\\\\n&= \\underset{\\boldsymbol{\\phi}}{\\mathrm{argmax}}\\left[\\prod_{i=1}^I P(y_i|\\boldsymbol{\\theta}_i)\\right]\\\\\n&= \\underset{\\boldsymbol{\\phi}}{\\mathrm{argmax}}\\left[\\prod_{i=1}^I P(y_i|f[x_i,\\phi])\\right].\n\\end{align*}\\]\nHere we are implicitly assuming that the data \\(\\{x_i,y_i\\}_{i=1}^I\\) are \\(independent\\) and \\(identically\\) \\(distributed\\) \\((i.i.d.)\\).\n\\[\\begin{align*}\nPr(y_1,y_2,\\ldots,y_I|x_1,x_2,\\ldots,x_I) = \\prod_{i=1}^I Pr(y_i|x_i)\n\\end{align*}\\]\nWe can equivalently maximize the logarithm of the likelihood:\n\\[\\begin{align*}\n\\hat{\\phi} & = \\operatorname*{argmax}_{\\phi} \\left[ \\prod_{i=1}^{I} P(y_i|f[x_i,\\phi]) \\right] \\\\\n& = \\operatorname*{argmax}_{\\phi} \\left[ \\log\\left[ \\prod_{i=1}^{I} P(y_i|f[x_i,\\phi]) \\right] \\right] \\\\\n& = \\operatorname*{argmax}_{\\phi} \\left[ \\sum_{i=1}^{I} \\log\\left[ P(y_i|f[x_i,\\phi]) \\right] \\right].\n\\end{align*}\\]\nBy convention, model fitting problems are framed in terms of minimizing a loss. To convert the maximum log-likelihood criterion to a minimization problem, we multiply by minus one, which gives us the negative \\(log\\)-\\(likelihood\\) \\(criterion\\):\n\\[\\begin{align*}\n\\hat{\\boldsymbol{\\phi}} &\\ =\\ \\underset{\\boldsymbol{\\phi}}{\\mathrm{argmin}}\\left[-\\sum_{i=1}^I\\mathrm{log}\\Bigl[P(y_i|f[x_i,\\phi])\\Bigr]\\right]\\\\\n&=\\ \\underset{\\boldsymbol{\\phi}}{\\mathrm{argmin}}\\Bigl[L[\\phi]\\Bigr],\n\\end{align*}\\]\nwhich is what forms the final loss function \\(L[\\phi]\\)."
  },
  {
    "objectID": "forblog/posts/index.html#recipe-for-constructing-loss-functions",
    "href": "forblog/posts/index.html#recipe-for-constructing-loss-functions",
    "title": "Introduction to Deep Neural Networks: Mathematical Foundations and Architectures",
    "section": "3. 3. Recipe for constructing loss functions",
    "text": "3. 3. Recipe for constructing loss functions\nThe recipe for constructing loss functions for training data \\(\\{x_i , y_i \\}\\) using the maximum likelihood approach is hence:\n\nChoose a suitable probability distribution \\(P(\\mathbf{y}|\\theta)\\) defined over the domain of the predictions \\(\\mathbf{y}\\) with distribution parameters \\(\\theta\\).\n\n\n\nSet the machine learning model \\(f[\\mathbf{x}, \\theta]\\) to predict one or more of these parameters, so \\(\\theta = f[\\mathbf{x}, \\theta]\\) and \\(P(y|θ) = P(y|f[\\mathbf{x}, \\theta])\\).\nTo train the model, find the network parameters \\(\\hat{\\phi}\\) that minimize the negative log-likelihood loss function over the training dataset pairs \\(\\{x_i , y_i \\}\\):\n\n\\[\\begin{align*}\n\\hat{\\phi} = \\underset{\\boldsymbol{\\phi}}{\\mathrm{argmin}}\\Bigl[L[\\phi]\\Bigr] = \\operatorname*{argmin}_{\\phi} \\left[ - \\sum_{i=1}^I \\log \\left[ Pr(y_i | f[x_i, \\phi]) \\right] \\right].\n\\end{align*}\\]\n\nTo perform inference for a new test example \\(\\mathbf{x}\\), return either the full distribution \\(P(\\mathbf{y}|f[\\mathbf{x}, \\phi])\\) or the value where this distribution is maximized.\n\n\n\n\n\n\n\nMetacognitive Insight\n\n\n\n\n\nThis section elegantly bridges probabilistic thinking with neural network training by: (1) framing predictions as distributions rather than point estimates, (2) demonstrating how log transformations convert products to more tractable sums, and (3) providing a clear 4-step recipe that connects theoretical probability to practical implementation. The i.i.d. assumption is crucially highlighted as it underpins the factorization enabling efficient optimization."
  },
  {
    "objectID": "forblog/posts/index.html#least-squares-loss-function",
    "href": "forblog/posts/index.html#least-squares-loss-function",
    "title": "Introduction to Deep Neural Networks: Mathematical Foundations and Architectures",
    "section": "4.1 Least squares loss function",
    "text": "4.1 Least squares loss function\nNow let’s perform some algebraic manipulations on the loss function. We seek:\n\\[\\begin{align*}\n\\hat{\\phi} = \\operatorname*{argmin}_{\\phi}\\left[-\\sum_{i=1}^{I}\\log\\left[\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp\\left[-\\frac{(y_{i}-f[x_{i},\\phi])^{2}}{2\\sigma^{2}}\\right]\\right]\\right]\n\\end{align*}\\]\n\\[\\begin{align*}\n= \\operatorname*{argmin}_{\\phi}\\left[-\\sum_{i=1}^{I}\\left(\\log\\left[\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\right]-\\frac{(y_{i}-f[x_{i},\\phi])^{2}}{2\\sigma^{2}}\\right)\\right]\n\\end{align*}\\]\n\\[\\begin{align*}\n= \\operatorname*{argmin}_{\\phi}\\left[-\\sum_{i=1}^{I}\\frac{(y_{i}-f[x_{i},\\phi])^{2}}{2\\sigma^{2}}\\right]\n\\end{align*}\\]\n\\[\\begin{align*}\n= \\operatorname*{argmin}_{\\phi}\\left[\\sum_{i=1}^{I}(y_{i}-f[x_{i},\\phi])^{2}\\right],\n\\end{align*}\\]\nwhere we removed the first term between the second and third lines because it doesn’t depend on \\(\\phi\\). We removed the denominator between the third and fourth lines, as this is just a constant positive scaling factor that does not affect the position of the minimum.\nThe result of these manipulations is the least squares loss function that we originally introduced when we discussed linear regression in chapter 2:\n\\[\\begin{align*}\nL[\\phi] = \\sum_{i=1}^{I}(y_{i}-f[x_{i},\\phi])^{2}.\n\\end{align*}\\]\nWe see that the least squares loss function follows naturally from the assumptions that the predictions are (i) independent and (ii) drawn from a normal distribution with mean \\(\\mu = f[x_{i},\\phi]\\).\n\n\n\n\n\n\n\nMetacognitive Insight\n\n\n\n\n\nThis example brilliantly connects probability theory with practical regression by: (1) showing how Gaussian assumptions naturally lead to least squares, (2) demonstrating careful mathematical reasoning through term elimination (constants don’t affect optimization), and (3) reinforcing the conceptual link between loss functions and probability distributions. The visual representation of the loss function grounds the abstract mathematics in concrete intuition."
  },
  {
    "objectID": "dictionary/terms/inference.html",
    "href": "dictionary/terms/inference.html",
    "title": "Inference",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/gradient.html",
    "href": "dictionary/terms/gradient.html",
    "title": "Gradient",
    "section": "",
    "text": "The gradients update the parameters by multiplying the two together. How much the gradients update the parameters is controlled by the learning rate.\nA positive gradient tells us that increasing the parameters will increase the loss. On the other hand, decreasing the parameters will decrease the loss.\nA negative gradient tells us that decreasing the parameters will increase the loss On the other hand, increasing the parameters will decrease the loss.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/bagging.html",
    "href": "dictionary/terms/bagging.html",
    "title": "Bagging",
    "section": "",
    "text": "“with replacement” means that if a model, for example, randomly chooses row number 5, another model can also randomly choose row number 5.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThrough this technique, each model ends up training on roughly 63% of the entire dataset.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/tabular_data.html",
    "href": "dictionary/terms/tabular_data.html",
    "title": "Tabular Data",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/oner_classifier.html",
    "href": "dictionary/terms/oner_classifier.html",
    "title": "OneR Classifier",
    "section": "",
    "text": "Below is an example determining whether a car is fast or slow.\n\n\n\n\n\nflowchart TB\n  A([Weight &lt; 2000kg])\n  B([Car Is Fast])\n  C([Car Is Slow])\n\n  A -- Yes --&gt; B\n  A -- No --&gt; C\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/tabular_model.html",
    "href": "dictionary/terms/tabular_model.html",
    "title": "Tabular Model",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/forward_pass.html",
    "href": "dictionary/terms/forward_pass.html",
    "title": "Forward Pass",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/numericalization.html",
    "href": "dictionary/terms/numericalization.html",
    "title": "Numericalization",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/linear_combination.html",
    "href": "dictionary/terms/linear_combination.html",
    "title": "Linear Combination",
    "section": "",
    "text": "\\[\n\\begin{bmatrix}\n1 \\\\\n2 \\\\\n3 \\\\\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n4 \\\\\n5 \\\\\n6 \\\\\n\\end{bmatrix}\n= (1 \\cdot 4) + (2 \\cdot 5) + (3 \\cdot 6) = 32\n\\]\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/metric.html",
    "href": "dictionary/terms/metric.html",
    "title": "Metric",
    "section": "",
    "text": "Examples of metrics are, but not limited to, accuracy, error rate, MAE, and MSE\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/decision_tree.html",
    "href": "dictionary/terms/decision_tree.html",
    "title": "Decision Tree",
    "section": "",
    "text": "A split is made for each feature in the data. If the feature of a certain data sample is larger than or less than the split for that respective feature, the next appropriate split is made.\nBelow is an example determining whether a car is fast or slow.\n\n\n\n\n\nflowchart TB\n  A([Weight &lt; 2000kg])\n  B([Is Engine Powerful])\n  C([Is Windy Day])\n  D1([Car Is Fast])\n  E1([Car Is Slow])\n  D2([Car Is Fast])\n  E2([Car Is Slow])\n\n\n  A -- Yes --&gt; B\n  A -- No --&gt; C\n  B -- Yes --&gt; D1\n  B -- No --&gt; E1\n  C -- Yes --&gt; E2\n  C -- No --&gt; D2\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/model.html",
    "href": "dictionary/terms/model.html",
    "title": "Model",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/decoder.html",
    "href": "dictionary/terms/decoder.html",
    "title": "Decoder (Transformers)",
    "section": "",
    "text": "To learn more about decoders, you can read this to the point rundown.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/weight_decay.html",
    "href": "dictionary/terms/weight_decay.html",
    "title": "Weight Decay",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/vector.html",
    "href": "dictionary/terms/vector.html",
    "title": "Vector",
    "section": "",
    "text": "The order of a vector is row by column.\nBelow is a \\(1 \\times 3\\) column vector. \\[\n\\begin{bmatrix}\n1 \\\\\n2 \\\\\n3 \\\\\n\\end{bmatrix}\n\\]\nBelow is a \\(3 \\times 1\\) row vector. \\[\n\\begin{bmatrix}\n1 & 2 & 3\n\\end{bmatrix}\n\\]\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/sampler.html",
    "href": "dictionary/terms/sampler.html",
    "title": "Sampler",
    "section": "",
    "text": "Metaphorically speaking, if we let a dataset be a warehouse, a dataloader be a human, a batch be a crate, and the sampler be the manager, then the manager is responsible for informing the human what items to gather from the warehouse, who then puts them into crates.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/encoder.html",
    "href": "dictionary/terms/encoder.html",
    "title": "Encoder (Transformers)",
    "section": "",
    "text": "To learn more about decoders, you can read this to the point rundown.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/gradient_boosting_machine_gbm.html",
    "href": "dictionary/terms/gradient_boosting_machine_gbm.html",
    "title": "Gradient Boosting Machine (GBM)",
    "section": "",
    "text": "The first model produces a prediction.\nThe difference between this prediction and the actual value is obtained.\nThe difference is now set as the target.\nThe next model now attempts to predict this difference.\nRepeat steps 2-4 for as many models as desired.\nSum all obtained differences.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhile this technique tends to produce better results, is more likely to overfit. This is because the machine is trying to minimize the difference between the predictions and actual values in the training set.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/root_mean_squared_error_rmse.html",
    "href": "dictionary/terms/root_mean_squared_error_rmse.html",
    "title": "Root Mean Squared Error (RMSE)",
    "section": "",
    "text": "It is calculated by:\n\nFirst taking the difference between each respective predicted and actual value.\nThen the squaring all obtained values.\nTaking the average.\nAnd finally taking the square root.\n\nLet’s say we have a set of predicted values \\(1, 2, 3, 4\\). The set of actual values is \\(1, 4, 3, 3\\)\n\n\\(1-1, 2-4, 3-3, 4-3, = 0, -2, 0, 1\\)\n\\((0)^2, (-2)^2, (0)^2, (1)^2 = 0, 4, 0, 1\\)\n\\(\\frac{0 + 4 + 0 + 1}{4} = \\frac{5}{4} = 1.25\\)\n\\(\\sqrt{1.25} \\approx 1.12\\)\n\nThis tells us, that on average, our set of predicted values is \\(1.12\\) units off from the actual values.\nIn a nutshell, you take the root of the mean of the square of the differences between the predicted and actual values.\n\nThe main difference between MSE and RMSE is that RMSE undoes the squaring step by taking the square root.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe reason the square value is taken is due to the averaging step. Let’s say the first predicted value is off from the first actual value by \\(-3\\) units. And let’s say that the second predicted value is off from the second actual value by \\(3\\) units.\nIf we didn’t take the square, the average would be zero \\(\\left( \\frac{-3 + 3}{2} = \\frac{0}{2} = 0 \\right)\\). This is incorrect as both values are off from the actual value.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/ensemble.html",
    "href": "dictionary/terms/ensemble.html",
    "title": "Ensemble",
    "section": "",
    "text": "The reason why this works is that some models will overestimate while others will underestimate, cancelling out each others’ errors.\nThere are different methods for ensembling.\n\n\n\n\n\n\nEnsembling only works when all models are independent of each other. That is, the models do not depend on one another.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/policy.html",
    "href": "dictionary/terms/policy.html",
    "title": "Policy (Reinforcement Learning)",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/activation_function.html",
    "href": "dictionary/terms/activation_function.html",
    "title": "Activation Function",
    "section": "",
    "text": "If there existed no activation function, there would be no point in having individual neurons, as the entire network would become a single, big linear equation.\n\n\n\n\n\n\nWith Activation Function\n\n\n\n\\(w_2 \\cdot \\text{activation}(w_1 x + b_1) + b_2\\)\n\n\n\n\n\n\n\n\nWithout Activation Function\n\n\n\n\\(w_2 \\cdot (w_1 x + b_1) + b_2 = w_2 w_1 x + w_2 b_1 + b_2\\)\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/error_rate.html",
    "href": "dictionary/terms/error_rate.html",
    "title": "Error Rate",
    "section": "",
    "text": "It can be calculated by dividing the number of incorrect predictions by the number of total predictions. Optionally multiply the result by 100 to obtain a percentage.\n\\[\n\\frac{\\text{number of incorrect predictions}}{\\text{number of total predictions}}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nError rate is also 1 - accuracy.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/named_entity_recognition.html",
    "href": "dictionary/terms/named_entity_recognition.html",
    "title": "Named Entity Recognition (NER)",
    "section": "",
    "text": "Take the sentence “Tim went to the Moon.” as an example. The sentence would first be broken into ‘Tim’, ‘went’, ‘to’, the’, ‘Moon’. The model could then give ‘Tim’ the label of ‘person’, and ‘Moon’ the label of ‘location’.\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/batch.html",
    "href": "dictionary/terms/batch.html",
    "title": "Batch",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/backward_pass.html",
    "href": "dictionary/terms/backward_pass.html",
    "title": "Backward Pass",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "dictionary/terms/tokenization.html",
    "href": "dictionary/terms/tokenization.html",
    "title": "Tokenization",
    "section": "",
    "text": "Note\n\n\n\n\n\nIf a word is too long or very uncommon, the word itself may be split. Take the word “supercalifragilisticexpialidocious” as an example. It could be split into “super”, “cali”, “fragilistic”, “expi”, “ali”, and “docious”.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "dictionary/terms/matrix.html",
    "href": "dictionary/terms/matrix.html",
    "title": "Matrix",
    "section": "",
    "text": "The order of a matrix is row by column.\nBelow is \\(3 \\times 2\\) matrix. \\[\n\\begin{bmatrix}\n1 & 2 \\\\\n3 & 4 \\\\\n5 & 6 \\\\\n\\end{bmatrix}\n\\]\nBelow is \\(2 \\times 3\\) matrix. \\[\n\\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n\\] \\end{bmatrix}\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Antonio Ortiz Romero",
    "section": "",
    "text": "AI Researcher applying physics-informed neural networks to geothermal energy optimization at IDAEA-CSIC. Combines mathematical modeling with practical AI experience from ETL systems and NLP tool development.\nCurrently expanding into scientific machine learning, with a vision to drive renewable energy innovation through computational methods.\n\n  SciML   –    PINNs   –    PyTorch \n\n\n\n\n Back to top"
  }
]