<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Antonio O.R.">
<meta name="description" content="Mathematical foundations of deep learning with focus on Physics-Informed Neural Networks">

<title>Introduction to Deep Neural Networks: Mathematical Foundations and Architectures â€“ Antonio O.R.</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-de84f8d6bb715db06a919283c2d1e787.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-553771c6479e51783e7ec80ad6077119.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Antonio O.R.</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> <i class="bi bi-house-door" role="img">
</i> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../forblog/index.html"> <i class="bi bi-newspaper" role="img">
</i> 
<span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../bitsandbobs/index.html"> <i class="bi bi-book" role="img">
</i> 
<span class="menu-text">Academic Works</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> <i class="bi bi-file-person" role="img">
</i> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#shallow-neural-networks" id="toc-shallow-neural-networks" class="nav-link active" data-scroll-target="#shallow-neural-networks">1. Shallow neural networks</a></li>
  <li><a href="#deep-neural-networks" id="toc-deep-neural-networks" class="nav-link" data-scroll-target="#deep-neural-networks">2. Deep neural networks</a>
  <ul class="collapse">
  <li><a href="#general-formulation" id="toc-general-formulation" class="nav-link" data-scroll-target="#general-formulation">General formulation</a></li>
  <li><a href="#shallow-vs.-deep-neural-networks" id="toc-shallow-vs.-deep-neural-networks" class="nav-link" data-scroll-target="#shallow-vs.-deep-neural-networks">Shallow vs.&nbsp;deep neural networks</a>
  <ul class="collapse">
  <li><a href="#advantages-of-deep-neural-networks-for-pinns" id="toc-advantages-of-deep-neural-networks-for-pinns" class="nav-link" data-scroll-target="#advantages-of-deep-neural-networks-for-pinns">Advantages of Deep Neural Networks for PINNs</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#loss-functions" id="toc-loss-functions" class="nav-link" data-scroll-target="#loss-functions">3. Loss functions</a>
  <ul class="collapse">
  <li><a href="#how-a-model-fmathbfx-phi-can-be-adapted-to-compute-a-probability-distribution" id="toc-how-a-model-fmathbfx-phi-can-be-adapted-to-compute-a-probability-distribution" class="nav-link" data-scroll-target="#how-a-model-fmathbfx-phi-can-be-adapted-to-compute-a-probability-distribution">3.1. How a model <span class="math inline">\(f[\mathbf{x}, \phi]\)</span> can be adapted to compute a probability distribution?</a></li>
  <li><a href="#maximum-likelihood-criterion" id="toc-maximum-likelihood-criterion" class="nav-link" data-scroll-target="#maximum-likelihood-criterion">3. 2. Maximum likelihood criterion</a></li>
  <li><a href="#recipe-for-constructing-loss-functions" id="toc-recipe-for-constructing-loss-functions" class="nav-link" data-scroll-target="#recipe-for-constructing-loss-functions">3. 3. Recipe for constructing loss functions</a></li>
  </ul></li>
  <li><a href="#example-univariate-regression" id="toc-example-univariate-regression" class="nav-link" data-scroll-target="#example-univariate-regression">4. Example: univariate regression</a>
  <ul class="collapse">
  <li><a href="#least-squares-loss-function" id="toc-least-squares-loss-function" class="nav-link" data-scroll-target="#least-squares-loss-function">4.1 Least squares loss function</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Introduction to Deep Neural Networks: Mathematical Foundations and Architectures</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>

<div>
  <div class="description">
    Mathematical foundations of deep learning with focus on Physics-Informed Neural Networks
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Antonio O.R. </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="shallow-neural-networks" class="level1">
<h1>1. Shallow neural networks</h1>
<p>Let <span class="math inline">\(\text{x}=(x_1,...,x_n)\in \mathbb{R}^n\)</span> be a multivariate input and <span class="math inline">\(\text{y}=(y_1,...,y_m)\in \mathbb{R}^m\)</span> a multivariate output <span class="math inline">\((n,m&gt;0)\)</span>. Shallow neural networks are functions with parameters</p>
<p><span class="math display">\[\begin{align*}
\phi=\{\phi_{10},...,\phi_{1d},..., \phi_{m0},...,\phi_{md},\theta_{10},..., \theta_{d0},...,\theta_{1n},..., \theta_{dn}\},
\end{align*}\]</span></p>
<p>where <span class="math inline">\(d\)</span> is the number of activation functions a[â€¢].</p>
<p>Case <span class="math inline">\(n=m=1, d=3\)</span>:</p>
<p><span class="math display">\[\begin{align*}
y &amp;= f[x, \boldsymbol{\phi}] \\
  &amp;= \phi_0 + \phi_1 a [\theta_{10} + \theta_{11} x] + \phi_2 a [\theta_{20} + \theta_{21} x] + \phi_3 a [\theta_{30} + \theta_{31} x].
\end{align*}\]</span></p>
<p><img src="images/ShallowNet.svg" class="img-fluid"></p>
<p>We can break down this calculation into three parts:</p>
<ol type="1">
<li>Compute three linear functions of the input data <span class="math inline">\((\theta_{10} + \theta_{11} x, \theta_{20} + \theta_{21} x, \theta_{30} + \theta_{31} x)\)</span></li>
<li>Pass the three results through an activation function a[â€¢]</li>
<li>Weight the three resulting activations with <span class="math inline">\(\theta_1\)</span> , <span class="math inline">\(\theta_2\)</span> , and <span class="math inline">\(\theta_3\)</span> , sum them, and add an offset <span class="math inline">\(\theta_0\)</span>.</li>
</ol>
<p>To complete the description, we must define the activation function a[â€¢]. There are many possibilities, but the hyperbolic tangent function is commonly used as an activation function in Physics-Informed Neural Networks (PINNs) due to its smooth and differentiable nature.</p>
<p><span class="math display">\[\begin{align*}
a[z] &amp;= \tanh[z] =
\begin{cases}
-1 &amp; z \ll 0 \\
z &amp; |z| \approx 0 \\
1 &amp; z \gg 0
\end{cases}
\end{align*}\]</span></p>
<p>Some advantages of using <span class="math inline">\(\tanh\)</span> in PINNs include:</p>
<ul>
<li><strong>Smoothness</strong>: Unlike ReLU, <span class="math inline">\(\tanh\)</span> is infinitely differentiable, which is beneficial for enforcing physical constraints that involve higher-order derivatives.</li>
<li><strong>Symmetry</strong>: It is symmetric around the origin, making it useful for capturing variations in both positive and negative directions.</li>
<li><strong>Better Gradient Flow</strong>: Compared to sigmoid, <span class="math inline">\(\tanh\)</span> has a steeper gradient, reducing the risk of vanishing gradients in deep networks.</li>
<li><strong>Physical Interpretability</strong>: In many physical systems, solutions naturally exhibit smooth transitions, which <span class="math inline">\(\tanh\)</span> can better approximate.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Metacognitive Insight
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This section masterfully bridges theoretical foundations (parameterized functions) with practical considerations (activation function selection), demonstrating how mathematical abstraction serves applied goals. The deliberate decomposition and domain-aware justification reveal expert knowledge organization - transforming complex concepts into teachable components while maintaining scientific rigor.</p>
</div>
</div>
</div>
</section>
<section id="deep-neural-networks" class="level1">
<h1>2. Deep neural networks</h1>
<section id="general-formulation" class="level3">
<h3 class="anchored" data-anchor-id="general-formulation">General formulation</h3>
<p>We will describe the vector of hidden units at layer <span class="math inline">\(k\)</span> as <span class="math inline">\(\mathbf{h}_k\)</span>, the vector of biases (intercepts) that contribute to hidden layer <span class="math inline">\(k+1\)</span> as <span class="math inline">\(\boldsymbol{\beta}_k\)</span>, and the weights (slopes) that are applied to the <span class="math inline">\(k^{th}\)</span> layer and contribute to the <span class="math inline">\((k+1)^{th}\)</span> layer as <span class="math inline">\(\boldsymbol{\Omega}_k\)</span>. A general deep network <span class="math inline">\(\mathbf{y} = f[\mathbf{x}, \phi]\)</span> with <span class="math inline">\(K\)</span> layers can now be written as:</p>
<span class="math display">\[\begin{aligned}
    \mathbf{h}_1 &amp;= a[\boldsymbol{\beta}_0 + \boldsymbol{\Omega}_0 \mathbf{x}] \\
    \mathbf{h}_2 &amp;= a[\boldsymbol{\beta}_1 + \boldsymbol{\Omega}_1 \mathbf{h}_1] \\
    \mathbf{h}_3 &amp;= a[\boldsymbol{\beta}_2 + \boldsymbol{\Omega}_2 \mathbf{h}_2] \\
    &amp;\vdots \\
    \mathbf{h}_K &amp;= a[\boldsymbol{\beta}_{K-1} + \boldsymbol{\Omega}_{K-1} \mathbf{h}_{K-1}] \\
    \mathbf{y} &amp;= \boldsymbol{\beta}_K + \boldsymbol{\Omega}_K \mathbf{h}_K.
\end{aligned}\]</span>
<p>The parameters <span class="math inline">\(\phi\)</span> of this model comprise all of these weight matrices and bias vectors:</p>
<span class="math display">\[\begin{aligned}
\phi = \{\beta_k, \Omega_k\}_{k=0}^{K}.
\end{aligned}\]</span>
<p>If the <span class="math inline">\(k^{th}\)</span> layer has <span class="math inline">\(D_k\)</span> hidden units, then the bias vector <span class="math inline">\(\boldsymbol{\beta}_{k-1}\)</span> will be of size <span class="math inline">\(D_k\)</span>. The last bias vector <span class="math inline">\(\boldsymbol{\beta}_k\)</span> has the size <span class="math inline">\(D_o\)</span> of the output. The first weight matrix <span class="math inline">\(\boldsymbol{\Omega}_0\)</span> has size <span class="math inline">\(D_1Ã—D_i\)</span>, where <span class="math inline">\(D_i\)</span> is the size of the input. The last weight matrix <strong>Î©â‚–</strong> is <em>Dâ‚€ Ã— Dâ‚–</em>, and the remaining matrices <span class="math inline">\(\boldsymbol{\Omega}_k\)</span> are <span class="math inline">\(D_{k+1}Ã—D_k\)</span> (figure 4.6).</p>
<p>We can equivalently write the network as a single function:</p>
<span class="math display">\[\begin{aligned}
    \mathbf{y} &amp;= \boldsymbol{\beta}_K + \boldsymbol{\Omega}_K a
    \left[\boldsymbol{\beta}_{K-1} + \boldsymbol{\Omega}_{K-1}
    a \left[\dots \boldsymbol{\beta}_2 + \boldsymbol{\Omega}_2
    a \left[\boldsymbol{\beta}_1 + \boldsymbol{\Omega}_1
    a [\boldsymbol{\beta}_0 + \boldsymbol{\Omega}_0 \mathbf{x}]
    \right] \dots \right] \right].
\end{aligned}\]</span>
<p><img src="images/DeepNet.svg" class="img-fluid"></p>
</section>
<section id="shallow-vs.-deep-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="shallow-vs.-deep-neural-networks">Shallow vs.&nbsp;deep neural networks</h2>
<section id="advantages-of-deep-neural-networks-for-pinns" class="level3">
<h3 class="anchored" data-anchor-id="advantages-of-deep-neural-networks-for-pinns">Advantages of Deep Neural Networks for PINNs</h3>
<p>Physics-Informed Neural Networks (PINNs) benefit significantly from deep architectures due to the following advantages:</p>
<section id="superior-function-approximation" class="level4">
<h4 class="anchored" data-anchor-id="superior-function-approximation">Superior Function Approximation</h4>
<ul>
<li>Deep networks can approximate complex physical functions by leveraging their ability to represent compositions of simpler functions.<br>
</li>
<li>This hierarchical representation aligns well with the multi-scale nature of many physical processes.</li>
</ul>
</section>
<section id="higher-expressiveness-with-fewer-parameters" class="level4">
<h4 class="anchored" data-anchor-id="higher-expressiveness-with-fewer-parameters">Higher Expressiveness with Fewer Parameters</h4>
<ul>
<li>Deep networks create significantly more linear regions than shallow networks with the same parameter count.<br>
</li>
<li>This allows PINNs to capture intricate solution structures more efficiently.<br>
</li>
<li>The increased expressiveness is particularly useful for solving PDEs with sharp gradients or discontinuities.</li>
</ul>
</section>
<section id="depth-efficiency-in-learning-complex-physics" class="level4">
<h4 class="anchored" data-anchor-id="depth-efficiency-in-learning-complex-physics">Depth Efficiency in Learning Complex Physics</h4>
<ul>
<li>Some physical problems require exponentially more neurons in a shallow network to match the performance of a deep network.<br>
</li>
<li>Deep architectures can learn structured physical relationships with fewer hidden units, making training more efficient.</li>
</ul>
</section>
<section id="handling-high-dimensional-and-structured-inputs" class="level4">
<h4 class="anchored" data-anchor-id="handling-high-dimensional-and-structured-inputs">Handling High-Dimensional and Structured Inputs</h4>
<ul>
<li>Many physical problems involve high-dimensional inputs (e.g., spatiotemporal fields).<br>
</li>
<li>Deep networks can efficiently process local information and integrate it into a global understanding, mimicking numerical solvers.<br>
</li>
<li>This property is crucial when solving PDEs over complex domains, as deep networks can better capture spatial correlations.</li>
</ul>
<p><img src="images/DeepVsShallow.svg" class="img-fluid"></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Metacognitive Insight
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The deep neural network formulation demonstrates expert-level knowledge organization by: (1) systematically decomposing hierarchical transformations through layer-wise notation, (2) explicitly tracking parameter dimensions to reinforce computational intuition, and (3) contrasting architectures to highlight inductive biases. The PINN-specific advantages reveal deep domain awareness - connecting abstract network properties to concrete physical modeling requirements through multi-scale reasoning and parameter efficiency arguments.</p>
</div>
</div>
</div>
</section>
</section>
</section>
</section>
<section id="loss-functions" class="level1">
<h1>3. Loss functions</h1>
<p>Consider a model <span class="math inline">\(f[\mathbf{x}, \phi]\)</span>. Until now, we have implied that the model directly computes a prediction <span class="math inline">\(\mathbf{y}\)</span>. We now shift perspective and consider the model as computing a conditional probability distribution <span class="math inline">\(P(\mathbf{y}|\mathbf{x})\)</span>. The loss encourages each training output <span class="math inline">\(y_i\)</span> to have a high probability under the distribution <span class="math inline">\(P(y_j |x_i )\)</span>.</p>
<p><img src="images/Loss.svg" class="img-fluid"></p>
<section id="how-a-model-fmathbfx-phi-can-be-adapted-to-compute-a-probability-distribution" class="level2">
<h2 class="anchored" data-anchor-id="how-a-model-fmathbfx-phi-can-be-adapted-to-compute-a-probability-distribution">3.1. How a model <span class="math inline">\(f[\mathbf{x}, \phi]\)</span> can be adapted to compute a probability distribution?</h2>
<ol type="1">
<li>Choose a parametric distribution <span class="math inline">\(P(\mathbf{y}|\theta)\)</span> defined on the output domain y,</li>
<li>Use the network to compute one or more of the parameters <span class="math inline">\(\theta\)</span> of this distribution.</li>
</ol>
<p>For example, suppose the prediction domain is the set of real numbers, so <span class="math inline">\(y\in\mathbb{R}\)</span>. Here, we might choose the univariate normal distribution, which is defined on <span class="math inline">\(\mathbb{R}\)</span>. This distribution is defined by the mean Âµ and variance <span class="math inline">\(\sigma^2\)</span> , so <span class="math inline">\(\theta = \{\mu, \sigma^2\}\)</span>. The machine learning model might predict the mean <span class="math inline">\(\mu\)</span>, and the variance <span class="math inline">\(\sigma^2\)</span> could be treated as an unknown constant.</p>
</section>
<section id="maximum-likelihood-criterion" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-criterion">3. 2. Maximum likelihood criterion</h2>
<p>The model now computes different distribution parameters $ _i = f[x_i , ]$ for each training input <span class="math inline">\(x_i\)</span> . Each observed training output <span class="math inline">\(y_i\)</span> should have high probability under its corresponding distribution <span class="math inline">\(P(y_i |\theta_i )\)</span>. Hence, we choose the model parameters <span class="math inline">\(\phi\)</span> so that they maximize the combined probability across all <span class="math inline">\(I\)</span> training examples:</p>
<p><span class="math display">\[\begin{align*}
\hat{\boldsymbol{\phi}} &amp;= \underset{\boldsymbol{\phi}}{\mathrm{argmax}}\left[\prod_{i=1}^I P(y_i|x_i)\right]\\
&amp;= \underset{\boldsymbol{\phi}}{\mathrm{argmax}}\left[\prod_{i=1}^I P(y_i|\boldsymbol{\theta}_i)\right]\\
&amp;= \underset{\boldsymbol{\phi}}{\mathrm{argmax}}\left[\prod_{i=1}^I P(y_i|f[x_i,\phi])\right].
\end{align*}\]</span></p>
<p>Here we are implicitly assuming that the data <span class="math inline">\(\{x_i,y_i\}_{i=1}^I\)</span> are <span class="math inline">\(independent\)</span> and <span class="math inline">\(identically\)</span> <span class="math inline">\(distributed\)</span> <span class="math inline">\((i.i.d.)\)</span>.</p>
<p><span class="math display">\[\begin{align*}
Pr(y_1,y_2,\ldots,y_I|x_1,x_2,\ldots,x_I) = \prod_{i=1}^I Pr(y_i|x_i)
\end{align*}\]</span></p>
<p>We can equivalently maximize the logarithm of the likelihood:</p>
<p><span class="math display">\[\begin{align*}
\hat{\phi} &amp; = \operatorname*{argmax}_{\phi} \left[ \prod_{i=1}^{I} P(y_i|f[x_i,\phi]) \right] \\
&amp; = \operatorname*{argmax}_{\phi} \left[ \log\left[ \prod_{i=1}^{I} P(y_i|f[x_i,\phi]) \right] \right] \\
&amp; = \operatorname*{argmax}_{\phi} \left[ \sum_{i=1}^{I} \log\left[ P(y_i|f[x_i,\phi]) \right] \right].
\end{align*}\]</span></p>
<p>By convention, model fitting problems are framed in terms of minimizing a loss. To convert the maximum log-likelihood criterion to a minimization problem, we multiply by minus one, which gives us the negative <span class="math inline">\(log\)</span>-<span class="math inline">\(likelihood\)</span> <span class="math inline">\(criterion\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\hat{\boldsymbol{\phi}} &amp;\ =\ \underset{\boldsymbol{\phi}}{\mathrm{argmin}}\left[-\sum_{i=1}^I\mathrm{log}\Bigl[P(y_i|f[x_i,\phi])\Bigr]\right]\\
&amp;=\ \underset{\boldsymbol{\phi}}{\mathrm{argmin}}\Bigl[L[\phi]\Bigr],
\end{align*}\]</span></p>
<p>which is what forms the final loss function <span class="math inline">\(L[\phi]\)</span>.</p>
</section>
<section id="recipe-for-constructing-loss-functions" class="level2">
<h2 class="anchored" data-anchor-id="recipe-for-constructing-loss-functions">3. 3. Recipe for constructing loss functions</h2>
<p>The recipe for constructing loss functions for training data <span class="math inline">\(\{x_i , y_i \}\)</span> using the maximum likelihood approach is hence:</p>
<ol type="1">
<li>Choose a suitable probability distribution <span class="math inline">\(P(\mathbf{y}|\theta)\)</span> defined over the domain of the predictions <span class="math inline">\(\mathbf{y}\)</span> with distribution parameters <span class="math inline">\(\theta\)</span>.</li>
</ol>
<p><img src="images/ConstructLoss.png" class="img-fluid"></p>
<ol start="2" type="1">
<li><p>Set the machine learning model <span class="math inline">\(f[\mathbf{x}, \theta]\)</span> to predict one or more of these parameters, so <span class="math inline">\(\theta = f[\mathbf{x}, \theta]\)</span> and <span class="math inline">\(P(y|Î¸) = P(y|f[\mathbf{x}, \theta])\)</span>.</p></li>
<li><p>To train the model, find the network parameters <span class="math inline">\(\hat{\phi}\)</span> that minimize the negative log-likelihood loss function over the training dataset pairs <span class="math inline">\(\{x_i , y_i \}\)</span>:</p></li>
</ol>
<p><span class="math display">\[\begin{align*}
\hat{\phi} = \underset{\boldsymbol{\phi}}{\mathrm{argmin}}\Bigl[L[\phi]\Bigr] = \operatorname*{argmin}_{\phi} \left[ - \sum_{i=1}^I \log \left[ Pr(y_i | f[x_i, \phi]) \right] \right].
\end{align*}\]</span></p>
<ol start="4" type="1">
<li>To perform inference for a new test example <span class="math inline">\(\mathbf{x}\)</span>, return either the full distribution <span class="math inline">\(P(\mathbf{y}|f[\mathbf{x}, \phi])\)</span> or the value where this distribution is maximized.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Metacognitive Insight
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This section elegantly bridges probabilistic thinking with neural network training by: (1) framing predictions as distributions rather than point estimates, (2) demonstrating how log transformations convert products to more tractable sums, and (3) providing a clear 4-step recipe that connects theoretical probability to practical implementation. The i.i.d. assumption is crucially highlighted as it underpins the factorization enabling efficient optimization.</p>
</div>
</div>
</div>
</section>
</section>
<section id="example-univariate-regression" class="level1">
<h1>4. Example: univariate regression</h1>
<p>The goal is to predict a single scalar output <span class="math inline">\(y\in\mathbb{R}\)</span> from input <span class="math inline">\(\mathbf{x}\)</span> using a model <span class="math inline">\(f[\mathbf{x},\phi]\)</span> with parameters <span class="math inline">\(\phi\)</span>. We select the univariate normal , which is defined over <span class="math inline">\(\mathbf{y}\in\mathbb{R}\)</span>. This distribution has two parameters (mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>) and has a probability density function:</p>
<p><span class="math display">\[\begin{align*}
Pr(y|\mu,\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left[-\frac{(y-\mu)^{2}}{2\sigma^{2}}\right].
\end{align*}\]</span></p>
<p>Second, we set the machine learning model <span class="math inline">\(f[\mathbf{x},\phi]\)</span> to compute one or more of the parameters of this distribution. Here, we just compute the mean so <span class="math inline">\(\mu = f[\mathbf{x},\phi]\)</span>:</p>
<p><span class="math display">\[\begin{align*}
Pr(y|f[\mathbf{x},\phi],\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left[-\frac{(y-f[\mathbf{x},\phi])^{2}}{2\sigma^{2}}\right].
\end{align*}\]</span></p>
<p>We aim to find the parameters <span class="math inline">\(\phi\)</span> that make the training data <span class="math inline">\(\{x_{i},y_{i}\}\)</span> most probable under this distribution. To accomplish this, we choose a loss function <span class="math inline">\(L[\boldsymbol{\phi}]\)</span> based on the negative log-likelihood:</p>
<p><span class="math display">\[\begin{align*}
L[\boldsymbol{\phi}] = -\sum_{i=1}^{I} \log\left[Pr(y_{i}|f[\mathbf{x},\phi],\sigma^{2})\right]
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
= -\sum_{i=1}^{I} \log\left[\frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left[-\frac{(y_{i}-f[\mathbf{x},\phi])^{2}}{2\sigma^{2}}\right]\right].
\end{align*}\]</span></p>
<p>When we train the model, we seek parameters <span class="math inline">\(\hat{\phi}\)</span> that minimize this loss.</p>
<p>The goal is to predict a single scalar output <span class="math inline">\(y\in\mathbb{R}\)</span> from input <span class="math inline">\(\mathbf{x}\)</span> using a model <span class="math inline">\(f[\mathbf{x},\phi]\)</span> with parameters <span class="math inline">\(\phi\)</span>. We select the univariate normal , which is defined over <span class="math inline">\(\mathbf{y}\in\mathbb{R}\)</span>. This distribution has two parameters (mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>) and has a probability density function:</p>
<p><span class="math display">\[\begin{align*}
Pr(y|\mu,\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left[-\frac{(y-\mu)^{2}}{2\sigma^{2}}\right].
\end{align*}\]</span></p>
<p>Second, we set the machine learning model <span class="math inline">\(f[\mathbf{x},\phi]\)</span> to compute one or more of the parameters of this distribution. Here, we just compute the mean so <span class="math inline">\(\mu = f[\mathbf{x},\phi]\)</span>:</p>
<p><span class="math display">\[\begin{align*}
Pr(y|f[\mathbf{x},\phi],\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left[-\frac{(y-f[\mathbf{x},\phi])^{2}}{2\sigma^{2}}\right].
\end{align*}\]</span></p>
<p>We aim to find the parameters <span class="math inline">\(\phi\)</span> that make the training data <span class="math inline">\(\{x_{i},y_{i}\}\)</span> most probable under this distribution. To accomplish this, we choose a loss function <span class="math inline">\(L[\boldsymbol{\phi}]\)</span> based on the negative log-likelihood:</p>
<p><span class="math display">\[\begin{align*}
L[\boldsymbol{\phi}] = -\sum_{i=1}^{I} \log\left[Pr(y_{i}|f[\mathbf{x},\phi],\sigma^{2})\right]
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
= -\sum_{i=1}^{I} \log\left[\frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left[-\frac{(y_{i}-f[\mathbf{x},\phi])^{2}}{2\sigma^{2}}\right]\right].
\end{align*}\]</span></p>
<p>When we train the model, we seek parameters <span class="math inline">\(\hat{\phi}\)</span> that minimize this loss.</p>
<section id="least-squares-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="least-squares-loss-function">4.1 Least squares loss function</h2>
<p>Now letâ€™s perform some algebraic manipulations on the loss function. We seek:</p>
<p><span class="math display">\[\begin{align*}
\hat{\phi} = \operatorname*{argmin}_{\phi}\left[-\sum_{i=1}^{I}\log\left[\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left[-\frac{(y_{i}-f[x_{i},\phi])^{2}}{2\sigma^{2}}\right]\right]\right]
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
= \operatorname*{argmin}_{\phi}\left[-\sum_{i=1}^{I}\left(\log\left[\frac{1}{\sqrt{2\pi\sigma^{2}}}\right]-\frac{(y_{i}-f[x_{i},\phi])^{2}}{2\sigma^{2}}\right)\right]
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
= \operatorname*{argmin}_{\phi}\left[-\sum_{i=1}^{I}\frac{(y_{i}-f[x_{i},\phi])^{2}}{2\sigma^{2}}\right]
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
= \operatorname*{argmin}_{\phi}\left[\sum_{i=1}^{I}(y_{i}-f[x_{i},\phi])^{2}\right],
\end{align*}\]</span></p>
<p>where we removed the first term between the second and third lines because it doesnâ€™t depend on <span class="math inline">\(\phi\)</span>. We removed the denominator between the third and fourth lines, as this is just a constant positive scaling factor that does not affect the position of the minimum.</p>
<p>The result of these manipulations is the least squares loss function that we originally introduced when we discussed linear regression in chapter 2:</p>
<p><span class="math display">\[\begin{align*}
L[\phi] = \sum_{i=1}^{I}(y_{i}-f[x_{i},\phi])^{2}.
\end{align*}\]</span></p>
<p>We see that the least squares loss function follows naturally from the assumptions that the predictions are (i) independent and (ii) drawn from a normal distribution with mean <span class="math inline">\(\mu = f[x_{i},\phi]\)</span>.</p>
<p><img src="images/LeastSquaresLoss.svg" class="img-fluid"></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Metacognitive Insight
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This example brilliantly connects probability theory with practical regression by: (1) showing how Gaussian assumptions naturally lead to least squares, (2) demonstrating careful mathematical reasoning through term elimination (constants donâ€™t affect optimization), and (3) reinforcing the conceptual link between loss functions and probability distributions. The visual representation of the loss function grounds the abstract mathematics in concrete intuition.</p>
</div>
</div>
</div>


<!-- -->

</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/toniortiz18\.github\.io\/portfolio\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Introduction to Deep Neural Networks: Mathematical Foundations and Architectures"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Antonio O.R."</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Mathematical foundations of deep learning with focus on Physics-Informed Neural Networks"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: flatly</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">    highlight-style: github</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu"># 1. Shallow neural networks</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>Let $\text{x}=(x_1,...,x_n)\in \mathbb{R}^n$ be a multivariate input and $\text{y}=(y_1,...,y_m)\in \mathbb{R}^m$ a multivariate output $(n,m&gt;0)$.</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>Shallow neural networks are functions with parameters</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>\phi=<span class="sc">\{</span>\phi_{10},...,\phi_{1d},..., \phi_{m0},...,\phi_{md},\theta_{10},..., \theta_{d0},...,\theta_{1n},..., \theta_{dn}<span class="sc">\}</span>,</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>where $d$ is the number of activation functions a<span class="co">[</span><span class="ot">â€¢</span><span class="co">]</span>.</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>Case $n=m=1, d=3$:</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>y &amp;= f<span class="co">[</span><span class="ot">x, \boldsymbol{\phi}</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>  &amp;= \phi_0 + \phi_1 a <span class="co">[</span><span class="ot">\theta_{10} + \theta_{11} x</span><span class="co">]</span> + \phi_2 a <span class="co">[</span><span class="ot">\theta_{20} + \theta_{21} x</span><span class="co">]</span> + \phi_3 a <span class="co">[</span><span class="ot">\theta_{30} + \theta_{31} x</span><span class="co">]</span>.</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/ShallowNet.svg)</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>We can break down this calculation into three parts:</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="ss">1.   </span>Compute three linear functions of the input data $(\theta_{10} + \theta_{11} x, \theta_{20} + \theta_{21} x, \theta_{30} + \theta_{31} x)$</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="ss">2.   </span>Pass the three results through an activation function a<span class="co">[</span><span class="ot">â€¢</span><span class="co">]</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Weight the three resulting activations with $\theta_1$ , $\theta_2$ , and $\theta_3$ , sum them, and add an offset $\theta_0$.</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>To complete the description, we must define the activation function a<span class="co">[</span><span class="ot">â€¢</span><span class="co">]</span>. There are many possibilities, but the hyperbolic tangent function is commonly used as an activation function in Physics-Informed Neural Networks (PINNs) due to its smooth and differentiable nature.</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>a<span class="co">[</span><span class="ot">z</span><span class="co">]</span> &amp;= \tanh<span class="co">[</span><span class="ot">z</span><span class="co">]</span> =</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>-1 &amp; z \ll 0 <span class="sc">\\</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>z &amp; |z| \approx 0 <span class="sc">\\</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>1 &amp; z \gg 0</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>Some advantages of using $\tanh$ in PINNs include:</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="ss">*    </span>**Smoothness**: Unlike ReLU, $\tanh$ is infinitely differentiable, which is beneficial for enforcing physical constraints that involve higher-order derivatives.</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>**Symmetry**: It is symmetric around the origin, making it useful for capturing variations in both positive and negative directions.</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">*    </span>**Better Gradient Flow**: Compared to sigmoid, $\tanh$ has a steeper gradient, reducing the risk of vanishing gradients in deep networks.</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="ss">*    </span>**Physical Interpretability**: In many physical systems, solutions naturally exhibit smooth transitions, which $\tanh$ can better approximate.</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="fu">## Metacognitive Insight</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>This section masterfully bridges theoretical foundations (parameterized functions) with practical considerations (activation function selection), demonstrating how mathematical abstraction serves applied goals. The deliberate decomposition and domain-aware justification reveal expert knowledge organization - transforming complex concepts into teachable components while maintaining scientific rigor.</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="fu"># 2. Deep neural networks</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="fu">### General formulation</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>We will describe the vector of hidden units at layer $k$ as $\mathbf{h}_k$,</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>the vector of biases (intercepts) that contribute to hidden layer $k+1$ as $\boldsymbol{\beta}_k$,</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>and the weights (slopes) that are applied to the $k^{th}$ layer and contribute</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>to the $(k+1)^{th}$ layer as $\boldsymbol{\Omega}_k$. A general deep network $\mathbf{y} = f<span class="co">[</span><span class="ot">\mathbf{x}, \phi</span><span class="co">]</span>$ with $K$ layers</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>can now be written as:</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>    \mathbf{h}_1 &amp;= a<span class="co">[</span><span class="ot">\boldsymbol{\beta}_0 + \boldsymbol{\Omega}_0 \mathbf{x}</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>    \mathbf{h}_2 &amp;= a<span class="co">[</span><span class="ot">\boldsymbol{\beta}_1 + \boldsymbol{\Omega}_1 \mathbf{h}_1</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>    \mathbf{h}_3 &amp;= a<span class="co">[</span><span class="ot">\boldsymbol{\beta}_2 + \boldsymbol{\Omega}_2 \mathbf{h}_2</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>    &amp;\vdots <span class="sc">\\</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>    \mathbf{h}_K &amp;= a[\boldsymbol{\beta}_{K-1} + \boldsymbol{\Omega}_{K-1} \mathbf{h}_{K-1}] <span class="sc">\\</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>    \mathbf{y} &amp;= \boldsymbol{\beta}_K + \boldsymbol{\Omega}_K \mathbf{h}_K.</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>The parameters $\phi$ of this model comprise all of these weight matrices and bias vectors:</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>\phi = <span class="sc">\{</span>\beta_k, \Omega_k<span class="sc">\}</span>_{k=0}^{K}.</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>If the $k^{th}$ layer has $D_k$ hidden units, then the bias vector $\boldsymbol{\beta}_{k-1}$ will be of size $D_k$. The last bias vector $\boldsymbol{\beta}_k$ has the size $D_o$ of the output. The first weight matrix $\boldsymbol{\Omega}_0$ has size $D_1Ã—D_i$, where $D_i$ is the size of the input. The last weight matrix **Î©â‚–** is *Dâ‚€ Ã— Dâ‚–*, and the remaining matrices $\boldsymbol{\Omega}_k$ are $D_{k+1}Ã—D_k$ (figure 4.6).</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>We can equivalently write the network as a single function:</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>    \mathbf{y} &amp;= \boldsymbol{\beta}_K + \boldsymbol{\Omega}_K a</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>    \left[\boldsymbol{\beta}_{K-1} + \boldsymbol{\Omega}_{K-1}</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>    a \left[\dots \boldsymbol{\beta}_2 + \boldsymbol{\Omega}_2</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>    a \left[\boldsymbol{\beta}_1 + \boldsymbol{\Omega}_1</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>    a <span class="co">[</span><span class="ot">\boldsymbol{\beta}_0 + \boldsymbol{\Omega}_0 \mathbf{x}</span><span class="co">]</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>    \right] \dots \right] \right].</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/DeepNet.svg)</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="fu">## Shallow vs. deep neural networks</span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="fu">### Advantages of Deep Neural Networks for PINNs</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>Physics-Informed Neural Networks (PINNs) benefit significantly from deep architectures due to the following advantages:</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Superior Function Approximation  </span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Deep networks can approximate complex physical functions by leveraging their ability to represent compositions of simpler functions.  </span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This hierarchical representation aligns well with the multi-scale nature of many physical processes.  </span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Higher Expressiveness with Fewer Parameters  </span></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Deep networks create significantly more linear regions than shallow networks with the same parameter count.  </span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This allows PINNs to capture intricate solution structures more efficiently.  </span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The increased expressiveness is particularly useful for solving PDEs with sharp gradients or discontinuities.  </span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Depth Efficiency in Learning Complex Physics  </span></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Some physical problems require exponentially more neurons in a shallow network to match the performance of a deep network.  </span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Deep architectures can learn structured physical relationships with fewer hidden units, making training more efficient.  </span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Handling High-Dimensional and Structured Inputs  </span></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Many physical problems involve high-dimensional inputs (e.g., spatiotemporal fields).  </span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Deep networks can efficiently process local information and integrate it into a global understanding, mimicking numerical solvers.  </span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This property is crucial when solving PDEs over complex domains, as deep networks can better capture spatial correlations.  </span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/DeepVsShallow.svg)</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="fu">## Metacognitive Insight</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>The deep neural network formulation demonstrates expert-level knowledge organization by: (1) systematically decomposing hierarchical transformations through layer-wise notation, (2) explicitly tracking parameter dimensions to reinforce computational intuition, and (3) contrasting architectures to highlight inductive biases. The PINN-specific advantages reveal deep domain awareness - connecting abstract network properties to concrete physical modeling requirements through multi-scale reasoning and parameter efficiency arguments.</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="fu"># 3. Loss functions</span></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>Consider a model $f<span class="co">[</span><span class="ot">\mathbf{x}, \phi</span><span class="co">]</span>$. Until now, we have</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>implied that the model directly computes a prediction $\mathbf{y}$. We now shift perspective and</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>consider the model as computing a conditional probability distribution $P(\mathbf{y}|\mathbf{x})$. The loss encourages each training output $y_i$ to have</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>a high probability under the distribution $P(y_j |x_i )$.</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/Loss.svg)</span></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3.1. How a model $f[\mathbf{x}, \phi]$ can be adapted to compute a probability distribution?</span></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="ss">1.   </span>Choose a parametric distribution $P(\mathbf{y}|\theta)$ defined on the output domain y,</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="ss">2.   </span>Use the network to compute one or more of the parameters $\theta$ of this distribution.</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>For example, suppose the prediction domain is the set of real numbers, so $y\in\mathbb{R}$.</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>Here, we might choose the univariate normal distribution, which is defined on $\mathbb{R}$. This</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>distribution is defined by the mean Âµ and variance $\sigma^2$ , so $\theta = <span class="sc">\{</span>\mu, \sigma^2<span class="sc">\}</span>$. The machine</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>learning model might predict the mean $\mu$, and the variance $\sigma^2$ could be treated as an</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>unknown constant.</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3. 2. Maximum likelihood criterion</span></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>The model now computes different distribution parameters $ \theta_i = f<span class="co">[</span><span class="ot">x_i , \phi</span><span class="co">]</span>$ for each training</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>input $x_i$ . Each observed training output $y_i$ should have high probability under its</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>corresponding distribution $P(y_i |\theta_i )$. Hence, we choose the model parameters $\phi$ so that</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>they maximize the combined probability across all $I$ training examples:</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>\hat{\boldsymbol{\phi}} &amp;= \underset{\boldsymbol{\phi}}{\mathrm{argmax}}\left<span class="co">[</span><span class="ot">\prod_{i=1}^I P(y_i|x_i)\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>&amp;= \underset{\boldsymbol{\phi}}{\mathrm{argmax}}\left<span class="co">[</span><span class="ot">\prod_{i=1}^I P(y_i|\boldsymbol{\theta}_i)\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>&amp;= \underset{\boldsymbol{\phi}}{\mathrm{argmax}}\left<span class="co">[</span><span class="ot">\prod_{i=1}^I P(y_i|f[x_i,\phi])\right</span><span class="co">]</span>.</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>Here we are implicitly assuming that the data $<span class="sc">\{</span>x_i,y_i<span class="sc">\}</span>_{i=1}^I$ are $independent$ and $identically$ $distributed$ $(i.i.d.)$.</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>Pr(y_1,y_2,\ldots,y_I|x_1,x_2,\ldots,x_I) = \prod_{i=1}^I Pr(y_i|x_i)</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>We can equivalently maximize the logarithm of the likelihood:</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>\hat{\phi} &amp; = \operatorname*{argmax}_{\phi} \left[ \prod_{i=1}^{I} P(y_i|f<span class="co">[</span><span class="ot">x_i,\phi</span><span class="co">]</span>) \right] <span class="sc">\\</span></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>&amp; = \operatorname*{argmax}_{\phi} \left[ \log\left[ \prod_{i=1}^{I} P(y_i|f<span class="co">[</span><span class="ot">x_i,\phi</span><span class="co">]</span>) \right] \right] <span class="sc">\\</span></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>&amp; = \operatorname*{argmax}_{\phi} \left[ \sum_{i=1}^{I} \log\left<span class="co">[</span><span class="ot"> P(y_i|f[x_i,\phi]) \right</span><span class="co">]</span> \right].</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>By convention, model fitting problems are framed in terms of</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>minimizing a loss. To convert the maximum log-likelihood criterion to a minimization</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>problem, we multiply by minus one, which gives us the negative $log$-$likelihood$ $criterion$:</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>\hat{\boldsymbol{\phi}} &amp;\ =\ \underset{\boldsymbol{\phi}}{\mathrm{argmin}}\left<span class="co">[</span><span class="ot">-\sum_{i=1}^I\mathrm{log}\Bigl[P(y_i|f[x_i,\phi])\Bigr</span><span class="co">]</span>\right]<span class="sc">\\</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>&amp;=\ \underset{\boldsymbol{\phi}}{\mathrm{argmin}}\Bigl<span class="co">[</span><span class="ot">L[\phi]\Bigr</span><span class="co">]</span>,</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>which is what forms the final loss function $L<span class="co">[</span><span class="ot">\phi</span><span class="co">]</span>$.</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3. 3. Recipe for constructing loss functions</span></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>The recipe for constructing loss functions for training data $<span class="sc">\{</span>x_i , y_i <span class="sc">\}</span>$ using the maximum likelihood approach is hence:</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="ss">1.   </span>Choose a suitable probability distribution $P(\mathbf{y}|\theta)$ defined over the domain of the predictions $\mathbf{y}$ with distribution parameters $\theta$.</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/ConstructLoss.png)</span></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Set the machine learning model $f<span class="co">[</span><span class="ot">\mathbf{x}, \theta</span><span class="co">]</span>$ to predict one or more of these parameters, so $\theta = f<span class="co">[</span><span class="ot">\mathbf{x}, \theta</span><span class="co">]</span>$ and $P(y|Î¸) = P(y|f<span class="co">[</span><span class="ot">\mathbf{x}, \theta</span><span class="co">]</span>)$.</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>To train the model, find the network parameters $\hat{\phi}$ that minimize the negative</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>log-likelihood loss function over the training dataset pairs $<span class="sc">\{</span>x_i , y_i <span class="sc">\}</span>$:</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>\hat{\phi} = \underset{\boldsymbol{\phi}}{\mathrm{argmin}}\Bigl<span class="co">[</span><span class="ot">L[\phi]\Bigr</span><span class="co">]</span> = \operatorname*{argmin}_{\phi} \left[ - \sum_{i=1}^I \log \left<span class="co">[</span><span class="ot"> Pr(y_i | f[x_i, \phi]) \right</span><span class="co">]</span> \right].</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>To perform inference for a new test example $\mathbf{x}$, return either the full distribution $P(\mathbf{y}|f<span class="co">[</span><span class="ot">\mathbf{x}, \phi</span><span class="co">]</span>)$ or the value where this distribution is maximized.</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="fu">## Metacognitive Insight</span></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>This section elegantly bridges probabilistic thinking with neural network training by: (1) framing predictions as distributions rather than point estimates, (2) demonstrating how log transformations convert products to more tractable sums, and (3) providing a clear 4-step recipe that connects theoretical probability to practical implementation. The i.i.d. assumption is crucially highlighted as it underpins the factorization enabling efficient optimization.</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a><span class="fu"># 4. Example: univariate regression</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>The goal is to predict a single scalar output $y\in\mathbb{R}$ from input $\mathbf{x}$ using a model $f<span class="co">[</span><span class="ot">\mathbf{x},\phi</span><span class="co">]</span>$ with parameters $\phi$. We select the univariate normal , which is defined over $\mathbf{y}\in\mathbb{R}$. This distribution has two parameters (mean $\mu$ and variance $\sigma^{2}$) and has a probability density function:</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>Pr(y|\mu,\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left<span class="co">[</span><span class="ot">-\frac{(y-\mu)^{2}}{2\sigma^{2}}\right</span><span class="co">]</span>.</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>Second, we set the machine learning model $f<span class="co">[</span><span class="ot">\mathbf{x},\phi</span><span class="co">]</span>$ to compute one or more of the parameters of this distribution. Here, we just compute the mean so $\mu = f<span class="co">[</span><span class="ot">\mathbf{x},\phi</span><span class="co">]</span>$:</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>Pr(y|f<span class="co">[</span><span class="ot">\mathbf{x},\phi</span><span class="co">]</span>,\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left<span class="co">[</span><span class="ot">-\frac{(y-f[\mathbf{x},\phi])^{2}}{2\sigma^{2}}\right</span><span class="co">]</span>.</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>We aim to find the parameters $\phi$ that make the training data $<span class="sc">\{</span>x_{i},y_{i}<span class="sc">\}</span>$ most probable under this distribution. To accomplish this, we choose a loss function $L<span class="co">[</span><span class="ot">\boldsymbol{\phi}</span><span class="co">]</span>$ based on the negative log-likelihood:</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>L<span class="co">[</span><span class="ot">\boldsymbol{\phi}</span><span class="co">]</span> = -\sum_{i=1}^{I} \log\left<span class="co">[</span><span class="ot">Pr(y_{i}|f[\mathbf{x},\phi],\sigma^{2})\right</span><span class="co">]</span></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>= -\sum_{i=1}^{I} \log\left<span class="co">[</span><span class="ot">\frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left[-\frac{(y_{i}-f[\mathbf{x},\phi])^{2}}{2\sigma^{2}}\right</span><span class="co">]</span>\right].</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>When we train the model, we seek parameters $\hat{\phi}$ that minimize this loss.</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>The goal is to predict a single scalar output $y\in\mathbb{R}$ from input $\mathbf{x}$ using a model $f<span class="co">[</span><span class="ot">\mathbf{x},\phi</span><span class="co">]</span>$ with parameters $\phi$. We select the univariate normal , which is defined over $\mathbf{y}\in\mathbb{R}$. This distribution has two parameters (mean $\mu$ and variance $\sigma^{2}$) and has a probability density function:</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>Pr(y|\mu,\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left<span class="co">[</span><span class="ot">-\frac{(y-\mu)^{2}}{2\sigma^{2}}\right</span><span class="co">]</span>.</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>Second, we set the machine learning model $f<span class="co">[</span><span class="ot">\mathbf{x},\phi</span><span class="co">]</span>$ to compute one or more of the parameters of this distribution. Here, we just compute the mean so $\mu = f<span class="co">[</span><span class="ot">\mathbf{x},\phi</span><span class="co">]</span>$:</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>Pr(y|f<span class="co">[</span><span class="ot">\mathbf{x},\phi</span><span class="co">]</span>,\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left<span class="co">[</span><span class="ot">-\frac{(y-f[\mathbf{x},\phi])^{2}}{2\sigma^{2}}\right</span><span class="co">]</span>.</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>We aim to find the parameters $\phi$ that make the training data $<span class="sc">\{</span>x_{i},y_{i}<span class="sc">\}</span>$ most probable under this distribution. To accomplish this, we choose a loss function $L<span class="co">[</span><span class="ot">\boldsymbol{\phi}</span><span class="co">]</span>$ based on the negative log-likelihood:</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>L<span class="co">[</span><span class="ot">\boldsymbol{\phi}</span><span class="co">]</span> = -\sum_{i=1}^{I} \log\left<span class="co">[</span><span class="ot">Pr(y_{i}|f[\mathbf{x},\phi],\sigma^{2})\right</span><span class="co">]</span></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>= -\sum_{i=1}^{I} \log\left<span class="co">[</span><span class="ot">\frac{1}{\sqrt{2\pi}\sigma^{2}} \exp\left[-\frac{(y_{i}-f[\mathbf{x},\phi])^{2}}{2\sigma^{2}}\right</span><span class="co">]</span>\right].</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>When we train the model, we seek parameters $\hat{\phi}$ that minimize this loss.</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="fu">## 4.1 Least squares loss function</span></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>Now let's perform some algebraic manipulations on the loss function. We seek:</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>\hat{\phi} = \operatorname*{argmin}_{\phi}\left[-\sum_{i=1}^{I}\log\left[\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left[-\frac{(y_{i}-f[x_{i},\phi])^{2}}{2\sigma^{2}}\right]\right]\right]</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>= \operatorname*{argmin}_{\phi}\left[-\sum_{i=1}^{I}\left(\log\left[\frac{1}{\sqrt{2\pi\sigma^{2}}}\right]-\frac{(y_{i}-f[x_{i},\phi])^{2}}{2\sigma^{2}}\right)\right]</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a>= \operatorname*{argmin}_{\phi}\left[-\sum_{i=1}^{I}\frac{(y_{i}-f[x_{i},\phi])^{2}}{2\sigma^{2}}\right]</span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>= \operatorname*{argmin}_{\phi}\left[\sum_{i=1}^{I}(y_{i}-f[x_{i},\phi])^{2}\right],</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>where we removed the first term between the second and third lines because it doesn't depend on $\phi$. We removed the denominator between the third and fourth lines, as this is just a constant positive scaling factor that does not affect the position of the minimum.</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>The result of these manipulations is the least squares loss function that we originally introduced when we discussed linear regression in chapter 2:</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>L<span class="co">[</span><span class="ot">\phi</span><span class="co">]</span> = \sum_{i=1}^{I}(y_{i}-f<span class="co">[</span><span class="ot">x_{i},\phi</span><span class="co">]</span>)^{2}.</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>We see that the least squares loss function follows naturally from the assumptions that the predictions are (i) independent and (ii) drawn from a normal distribution with mean $\mu = f<span class="co">[</span><span class="ot">x_{i},\phi</span><span class="co">]</span>$.</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/LeastSquaresLoss.svg)</span></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="fu">## Metacognitive Insight</span></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>This example brilliantly connects probability theory with practical regression by: (1) showing how Gaussian assumptions naturally lead to least squares, (2) demonstrating careful mathematical reasoning through term elimination (constants don't affect optimization), and (3) reinforcing the conceptual link between loss functions and probability distributions. The visual representation of the loss function grounds the abstract mathematics in concrete intuition.</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>:::</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><small> <a href="https://toniortiz18.github.io/momentum_portfolio/">Antonio Ortiz Romero</a> | Titulado Superior @ IDAEA-CSIC | <i class="fas fa-flask"></i> Computational Physics | <i class="fas fa-code"></i> AI Python Developer </small></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>